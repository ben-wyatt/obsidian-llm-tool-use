{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5f06d914473b44028e71a889526105d9\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve Azure OpenAI credentials\n",
    "api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "api_base = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "deployment_name = 'gpt-4.1-mini'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is Paris.\n"
     ]
    }
   ],
   "source": [
    "from openai import AzureOpenAI\n",
    "client = AzureOpenAI(azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"), azure_deployment=deployment_name, api_version=\"2023-03-15-preview\")\n",
    "\n",
    "response =client.chat.completions.create(\n",
    "    model=\"gpt-4.1\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"What is the capital of France?\"}]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "APIRemovedInV1",
     "evalue": "\n\nYou tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAPIRemovedInV1\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     11\u001b[39m deployment_name = \u001b[33m\"\u001b[39m\u001b[33mgpt-4.1-mini\u001b[39m\u001b[33m\"\u001b[39m  \u001b[38;5;66;03m# Replace with your deployment name\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Make a request to the Azure OpenAI service\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m response = \u001b[43mopenai\u001b[49m\u001b[43m.\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdeployment_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Use \"engine\" instead of \"model\" for Azure\u001b[39;49;00m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mWhat is the capital of France?\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# Print the response\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[38;5;28mprint\u001b[39m(response[\u001b[33m\"\u001b[39m\u001b[33mchoices\u001b[39m\u001b[33m\"\u001b[39m][\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mmessage\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repos/personal/obsidian-llm-tool-use/.venv/lib/python3.12/site-packages/openai/lib/_old_api.py:39\u001b[39m, in \u001b[36mAPIRemovedInV1Proxy.__call__\u001b[39m\u001b[34m(self, *_args, **_kwargs)\u001b[39m\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *_args: Any, **_kwargs: Any) -> Any:\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m APIRemovedInV1(symbol=\u001b[38;5;28mself\u001b[39m._symbol)\n",
      "\u001b[31mAPIRemovedInV1\u001b[39m: \n\nYou tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "# Set your Azure OpenAI credentials\n",
    "openai.api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")  # Or set it directly as a string\n",
    "openai.api_base = os.getenv(\"AZURE_OPENAI_ENDPOINT\")  # e.g., \"https://<your-resource-name>.openai.azure.com\"\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_version = \"2023-03-15-preview\"\n",
    "\n",
    "# Specify the deployment name of your Azure OpenAI model\n",
    "deployment_name = \"gpt-4.1-mini\"  # Replace with your deployment name\n",
    "\n",
    "# Make a request to the Azure OpenAI service\n",
    "response = openai.ChatCompletion.create(\n",
    "    engine=deployment_name,  # Use \"engine\" instead of \"model\" for Azure\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"What is the capital of France?\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Print the response\n",
    "print(response[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The capital of France is Paris.']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test azure openai using DSPy\n",
    "import dspy\n",
    "\n",
    "\n",
    "# Handle missing environment variables\n",
    "if not api_key:\n",
    "    raise ValueError(\"AZURE_OPENAI_API_KEY environment variable is not set.\")\n",
    "if not api_base:\n",
    "    raise ValueError(\"AZURE_OPENAI_ENDPOINT environment variable is not set.\")\n",
    "if not deployment_name:\n",
    "    raise ValueError(\"AZURE_OPENAI_DEPLOYMENT environment variable is not set.\")\n",
    "\n",
    "# Initialize the LM with Azure OpenAI\n",
    "azure_lm = dspy.LM(\n",
    "    model=f\"azure/{deployment_name}\",\n",
    "    api_key=api_key,\n",
    "    api_base=api_base,\n",
    "    api_version=\"2023-03-15-preview\"\n",
    ")\n",
    "\n",
    "# Configure DSPy to use this Azure LM\n",
    "dspy.configure(lm=azure_lm)\n",
    "\n",
    "azure_lm(\"What is the capital of France?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Key: 5f06d914473b44028e71a889526105d9\n",
      "API Base: https://usecoai50qaoa01.openai.azure.com/\n",
      "Deployment Name: gpt-4.1-mini\n",
      "Response: Prediction(\n",
      "    obs_note=Prediction(\n",
      "    reasoning='The context provides a sample long text that needs to be converted into Obsidian markdown format. There are no existing notes to link to, so the note will be a standalone markdown note. The note should be formatted clearly with a title and the text content. Since no specific title is given, a generic title like \"Sample Long Text\" can be used.',\n",
      "    obs_note='# Sample Long Text\\n\\nThis is a sample long text that will be converted into Obsidian markdown format.  \\nIt should include links to existing notes where relevant.'\n",
      "),\n",
      "    context='\\nThis is a sample long text that will be converted into Obsidian markdown format.\\nIt should include links to existing notes where relevant.\\n',\n",
      "    note_list=[]\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import dspy\n",
    "from dspy import Signature, InputField, OutputField, ChainOfThought\n",
    "import os\n",
    "from dspy_modules.note_gen import NoteGenerator\n",
    "from tools.md_files import get_notes_list, create_note\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "api_base = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "deployment_name = 'gpt-4.1-mini'\n",
    "\n",
    "\n",
    "print(\"API Key:\", api_key)\n",
    "print(\"API Base:\", api_base)\n",
    "print(\"Deployment Name:\", deployment_name)\n",
    "\n",
    "\n",
    "if not api_key:\n",
    "    raise ValueError(\"AZURE_OPENAI_API_KEY environment variable is not set.\")\n",
    "if not api_base:\n",
    "    raise ValueError(\"AZURE_OPENAI_ENDPOINT environment variable is not set.\")\n",
    "if not deployment_name:\n",
    "    raise ValueError(\"AZURE_OPENAI_DEPLOYMENT environment variable is not set.\")\n",
    "\n",
    "\n",
    "lm = dspy.LM(\n",
    "    model=f\"azure/{deployment_name}\",\n",
    "    api_key=api_key,\n",
    "    api_base=api_base,\n",
    "    api_version=\"2023-03-15-preview\" \n",
    ")\n",
    "\n",
    "dspy.configure(lm=lm)\n",
    "\n",
    "\n",
    "\n",
    "long_text = \"\"\"\n",
    "This is a sample long text that will be converted into Obsidian markdown format.\n",
    "It should include links to existing notes where relevant.\n",
    "\"\"\"\n",
    "note_name = \"sample_obsidian_note\"\n",
    "\n",
    "\n",
    "note_generator = NoteGenerator()\n",
    "response = note_generator(context=long_text, note_list=get_notes_list())\n",
    "obsidian_note = response.obs_note\n",
    "print(f\"Response: {response}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    reasoning='The context provides a sample long text that needs to be converted into Obsidian markdown format. There are no existing notes to link to, so the note will be a standalone markdown note. The note should be formatted clearly with a title and the text content. Since no specific title is given, a generic title like \"Sample Long Text\" can be used.',\n",
       "    obs_note='# Sample Long Text\\n\\nThis is a sample long text that will be converted into Obsidian markdown format.  \\nIt should include links to existing notes where relevant.'\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.obs_note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the generated note to the vault\n",
    "create_note(note_name, obsidian_note)\n",
    "print(f\"Note '{note_name}' created successfully in the vault.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
