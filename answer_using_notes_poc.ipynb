{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3d053d1",
   "metadata": {},
   "source": [
    "I want to have a more intuitive way to search through my notes.\n",
    "Some facts about my notes:\n",
    "- I have a daily note that is formatted like: 2025-11-25. this daily note includes my todo list, work log, thinking, meeting notes, media, and a list of notes that were created/modified that day\n",
    "- \n",
    "\n",
    "\n",
    "The thing needs to be able to keyword search or something like that for a starting point. Then search for the next step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54cfa086",
   "metadata": {},
   "source": [
    "\n",
    "Give a ReAct agent access to database of markdown notes with information on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f9e8092",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "os.environ[\"VAULT_PATH\"]=\"~/Obsidian/Notes Vault\"\n",
    "\n",
    "import dspy\n",
    "azure_lm = dspy.LM(\n",
    "    model=f\"azure/gpt-4.1\",\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    api_base=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_version=\"2023-03-15-preview\"\n",
    ")\n",
    "dspy.configure(lm=azure_lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b95df70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a vector database of my notes\n",
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "sentences = [\"Paris is in France\",\"Houston is in Texas\",\"Berlin is in Germany\",\"Tokyo is in Japan\"]\n",
    "sentences_meta =[\"France\",\"Texas\",\"Germany\",\"Japan\"]\n",
    "\n",
    "embeddings = model.encode(sentences,convert_to_numpy=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4b5134",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the index\n",
    "import faiss\n",
    "import pickle\n",
    "\n",
    "dim = embeddings.shape[1]\n",
    "index= faiss.IndexFlatL2(dim)\n",
    "index.add(embeddings)\n",
    "\n",
    "faiss.write_index(index, \"data/faiss/capital_index.faiss\")\n",
    "with open(\"data/faiss/capital_meta.pkl\", \"wb\") as f:\n",
    "    pickle.dump(sentences_meta, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe25540",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read/use the index\n",
    "import faiss\n",
    "import pickle\n",
    "\n",
    "index = faiss.read_index('data/faiss/capital_index.faiss')\n",
    "with open(\"data/faiss/capital_meta.pkl\", \"rb\") as f:\n",
    "    sentences_meta = pickle.load(f)\n",
    "query = \"Startups\"\n",
    "query_vec = model.encode([query],convert_to_numpy=True)\n",
    "top_k = 2\n",
    "result = index.search(query_vec, top_k)\n",
    "D,I = index.search(query_vec, top_k)\n",
    "for idx in I[0]:\n",
    "    print(sentences_meta[idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02d44b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now use it on my notes\n",
    "from tools.md_files import get_notes_list, get_note_content\n",
    "\n",
    "notes_list = get_notes_list()\n",
    "note_content=[]\n",
    "for note in notes_list:\n",
    "    print(note)\n",
    "    content = get_note_content(note)\n",
    "    content=note+'\\n\\n'+content\n",
    "    note_content.append(content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de4c3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = model.encode(note_content,convert_to_numpy=True)\n",
    "\n",
    "dim = embeddings.shape[1]\n",
    "index= faiss.IndexFlatL2(dim)\n",
    "index.add(embeddings)\n",
    "\n",
    "faiss.write_index(index, \"data/faiss/small_notes_index.faiss\")\n",
    "with open(\"data/faiss/small_notes_meta.pkl\", \"wb\") as f:\n",
    "    pickle.dump(notes_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a775a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"reinforcement learning\"\n",
    "query_vec = model.encode([query],convert_to_numpy=True)\n",
    "top_k = 5\n",
    "result = index.search(query_vec, top_k)\n",
    "D,I = index.search(query_vec, top_k)\n",
    "for idx in I[0]:\n",
    "    print(notes_list[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148a3658",
   "metadata": {},
   "source": [
    "Now lets functionize this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957c1837",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reindex_notes():\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    import faiss\n",
    "    import pickle\n",
    "    from tools.md_files import get_notes_list, get_note_content\n",
    "    model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "    notes_list = get_notes_list()\n",
    "    note_content=[]\n",
    "    for note in notes_list:\n",
    "        content = get_note_content(note)\n",
    "        content=note+'\\n\\n'+content\n",
    "        note_content.append(content)\n",
    "\n",
    "    embeddings = model.encode(note_content,convert_to_numpy=True)\n",
    "\n",
    "    dim = embeddings.shape[1]\n",
    "    index= faiss.IndexFlatL2(dim)\n",
    "    index.add(embeddings)\n",
    "\n",
    "    faiss.write_index(index, \"data/faiss/notes_index.faiss\")\n",
    "    with open(\"data/faiss/notes_meta.pkl\", \"wb\") as f:\n",
    "        pickle.dump(notes_list, f)\n",
    "\n",
    "def search_notes(query: str, top_k: int = 5):\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    import faiss\n",
    "    import pickle\n",
    "    model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "    index = faiss.read_index('data/faiss/notes_index.faiss')\n",
    "    with open(\"data/faiss/notes_meta.pkl\", \"rb\") as f:\n",
    "        notes_list = pickle.load(f)\n",
    "    query_vec = model.encode([query],convert_to_numpy=True)\n",
    "    result = index.search(query_vec, top_k)\n",
    "    D,I = index.search(query_vec, top_k)\n",
    "    return [notes_list[idx] for idx in I[0]]\n",
    "search_notes(\"reinforcement learning\")\n",
    "\n",
    "\n",
    "#done! moved this to tools/md_files.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce160e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.md_files import search_notes,get_note_content\n",
    "\n",
    "class NoteResearcher(dspy.Signature):\n",
    "    \"\"\"Read through notes to answer a question\"\"\"\n",
    "    question: str = dspy.InputField(description=\"The question that needs to be answered.\")\n",
    "    answer: str = dspy.OutputField(description=\"The answer to the question.\")\n",
    "\n",
    "agent = dspy.ReAct(\n",
    "    NoteResearcher,\n",
    "    tools=[search_notes,get_note_content]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11d1d045",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = agent(question=\"What is the difference between no-interaction and late-interaction retrieval models?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90999846",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dspy.primitives.prediction.Prediction"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "813aa709",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    trajectory={'thought_0': 'To answer what you were working on June 26th, I should search for notes that mention \"June 26th\" or are dated around that time. I\\'ll start by searching for notes with \"June 26\" as the query.', 'tool_name_0': 'search_notes', 'tool_args_0': {'query': 'June 26', 'top_k': 5}, 'observation_0': ['2025-05-04', '2025-06-21', 'Template/Template, Testing', 'Untitled 14', 'Untitled 13'], 'thought_1': 'None of the note titles directly reference June 26th, but the note titled \"2025-06-21\" is close in date and may contain information about work done around June 26th. I will check the content of \"2025-06-21\" to see if it mentions ongoing or upcoming work for June 26th.', 'tool_name_1': 'get_note_content', 'tool_args_1': {'note_name': '2025-06-21'}, 'observation_1': '[[2025-06-20]] - [[2025-06-22]]', 'thought_2': 'The note \"2025-06-21\" references the dates June 20th to June 22nd, but does not provide specific content about June 26th. I should try searching for notes with the query \"June\" to see if there are any notes from late June that might cover June 26th or mention work around that date.', 'tool_name_2': 'search_notes', 'tool_args_2': {'query': 'June', 'top_k': 5}, 'observation_2': ['2025-05-04', '2025-06-21', 'Untitled 14', 'Untitled 12', 'Untitled 2'], 'thought_3': 'There is a note titled \"Untitled 14\" that appeared in both search results and may contain relevant information about June 26th. Since it is not dated, I should check its content to see if it references June 26th or work around that time.', 'tool_name_3': 'get_note_content', 'tool_args_3': {'note_name': 'Untitled 14'}, 'observation_3': '', 'thought_4': 'The content of \"Untitled 14\" is empty, so it does not provide any information about what you were working on June 26th. I should check the next most relevant undated note from the search, \"Untitled 12\", to see if it contains any references to June 26th or work around that time.', 'tool_name_4': 'get_note_content', 'tool_args_4': {'note_name': 'Untitled 12'}, 'observation_4': ''},\n",
       "    reasoning='I searched for notes referencing \"June 26\" and \"June\" to find any records of what you were working on that day. The only dated note near June 26th was \"2025-06-21\", which covers June 20th to June 22nd but does not mention June 26th or any ongoing work. I also checked undated notes \"Untitled 14\" and \"Untitled 12\", but both were empty and provided no information. There are no notes available that mention June 26th or provide details about your work on that date.',\n",
       "    answer='There is no information in your notes about what you were working on June 26th.'\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = agent(question=\"What was I working on June 26th?\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7eea2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thought_0: To answer what you were working on June 26th, I should search for notes that mention \"June 26th\" or are dated around that time. I'll start by searching for notes with \"June 26\" as the query.\n",
      "tool_name_0: search_notes\n",
      "tool_args_0: {'query': 'June 26', 'top_k': 5}\n",
      "observation_0: ['2025-05-04', '2025-06-21', 'Template/Template, Testing', 'Untitled 14', 'Untitled 13']\n",
      "thought_1: None of the note titles directly reference June 26th, but the note titled \"2025-06-21\" is close in date and may contain information about work done around June 26th. I will check the content of \"2025-06-21\" to see if it mentions ongoing or upcoming work for June 26th.\n",
      "tool_name_1: get_note_content\n",
      "tool_args_1: {'note_name': '2025-06-21'}\n",
      "observation_1: [[2025-06-20]] - [[2025-06-22]]\n",
      "thought_2: The note \"2025-06-21\" references the dates June 20th to June 22nd, but does not provide specific content about June 26th. I should try searching for notes with the query \"June\" to see if there are any notes from late June that might cover June 26th or mention work around that date.\n",
      "tool_name_2: search_notes\n",
      "tool_args_2: {'query': 'June', 'top_k': 5}\n",
      "observation_2: ['2025-05-04', '2025-06-21', 'Untitled 14', 'Untitled 12', 'Untitled 2']\n",
      "thought_3: There is a note titled \"Untitled 14\" that appeared in both search results and may contain relevant information about June 26th. Since it is not dated, I should check its content to see if it references June 26th or work around that time.\n",
      "tool_name_3: get_note_content\n",
      "tool_args_3: {'note_name': 'Untitled 14'}\n",
      "observation_3: \n",
      "thought_4: The content of \"Untitled 14\" is empty, so it does not provide any information about what you were working on June 26th. I should check the next most relevant undated note from the search, \"Untitled 12\", to see if it contains any references to June 26th or work around that time.\n",
      "tool_name_4: get_note_content\n",
      "tool_args_4: {'note_name': 'Untitled 12'}\n",
      "observation_4: \n"
     ]
    }
   ],
   "source": [
    "traj = result.trajectory\n",
    "for step_key, step_value in traj.items():\n",
    "    if \"observation\" in step_key and len(step_value) > 300:\n",
    "        step_value = step_value[:300] + \"...\"\n",
    "    print(f\"{step_key}: {step_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e396791",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ce10529b",
   "metadata": {},
   "source": [
    "This second example shows exactly the problem that I was looking at earlier: vector search doesn't work incredibly well for dictionary mentions like dates and names.  But it's very good at picking up the *vibe*.\n",
    "\n",
    "So next steps in this process is making better retrieval.  How can I efficiently do this?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d892cf3",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
