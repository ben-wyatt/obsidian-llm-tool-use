{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a865a950",
   "metadata": {},
   "source": [
    "Links\n",
    "- [DSPy Documentation](https://dspy.ai/#__tabbed_1_4)\n",
    "\n",
    "\n",
    "Double Saved to `obsidian-llm-tool-use` Github repo and my personal note vault in obsidian via:\n",
    "```bash\n",
    "jupytext --to markdown dspy_modules/intro_to_dspy.ipynb -o ~/Obsidian/Notes\\ Vault/intro_to_dspy.md\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09674048",
   "metadata": {},
   "source": [
    "First, import the package and setup your llm calling configuration. For this, we'll be using ollama.\n",
    "\n",
    "Make sure to spin up your ollama server using\n",
    "```bash\n",
    "ollama start\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de02a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib.metadata\n",
    "print(importlib.metadata.version('dspy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5efa3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "lm = dspy.LM('openai/qwen2.5:7b-instruct-q4_K_M', \n",
    "             api_base='http://localhost:11434/v1', \n",
    "             api_key='', \n",
    "             cache=False)\n",
    "\n",
    "dspy.configure(lm=lm)\n",
    "dspy.enable_logging()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e980b6f0",
   "metadata": {},
   "source": [
    "Lets do the basic prompt-response: just use the `lm` as a function!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8b1023",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm(\"Say this is a test!\", temperature=0.7)  # => ['This is a test!']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78536af",
   "metadata": {},
   "source": [
    "Super compact syntax.\n",
    "\n",
    "You could just use this as a nice way to make your LLM calls a bit more pythonic.\n",
    "\n",
    "You can also send using the chat completions formatting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf846a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm(messages=[{\"role\": \"user\", \"content\": \"Say this is a test!\"}])  # => ['This is a test!']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555bb837",
   "metadata": {},
   "source": [
    "Ok now to the first main topic:\n",
    "\n",
    "## Modules\n",
    "\n",
    "Modules help you describe AI behavior as *code*. not *strings*.\n",
    "\n",
    "You specify a *Signature*: a string that defines an action via inputs and outputs behavior: `\"question -> answer: float\"`\n",
    "\n",
    "Then you select a *Module* to assign a strategy for invoking the LLM. `Predict` is the simplest one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa9660e",
   "metadata": {},
   "outputs": [],
   "source": [
    "solve_math = dspy.Predict(\"question -> answer: float\")\n",
    "result = solve_math(question=\"What is 1 + 1?\")\n",
    "print(result.completions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225e99f1",
   "metadata": {},
   "source": [
    "A Module:\n",
    "- wraps a signature.\n",
    "- is callable\n",
    "- carries \"learnable parameters\" that DSPy can run optimization on.\n",
    "- composes: modules call other modules, can be stored as `json`, or be nested inside larger `dspy.Program` graphs.\n",
    "- persists: `module.save()`/`load()` for controlling state.\n",
    "\n",
    "\n",
    "There's a few really powerful primative ones already implemented, like `dspy.ChainOfThought`. It automatically:\n",
    "1. Inserts an instruction telling the LLM to show its reasoning.\n",
    "2. Adds an implicit extra output field called `reasoning`.\n",
    "3. Returns both the reasoning and the final answer, while still respecting the original signature.\n",
    "\n",
    "So that's why it won't be very good for:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e7d7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = solve_math(question=\"What is the third root of 963261?\")\n",
    "print(result.completions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6218c0e8",
   "metadata": {},
   "source": [
    "But you can get pretty creative with the signatures.  LLM act as this universal function approximator written via English.  Modules try to shape that approximator into a math function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce8591a",
   "metadata": {},
   "outputs": [],
   "source": [
    "solve_riddle = dspy.Predict(\"riddle -> answer\")\n",
    "print(solve_riddle(riddle=\"What has keys but can't open locks?\").answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff51c38",
   "metadata": {},
   "source": [
    "In your *Signature* you can list multiple fields: `\"context: list[str], question -> answer\"` or omit the types if they're strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa95f473",
   "metadata": {},
   "outputs": [],
   "source": [
    "emojify = dspy.Predict(\"story -> emoji_sequence\")\n",
    "\n",
    "story=\"\"\"You're walking in the woods\n",
    "There's no one around and your phone is dead\n",
    "Out of the corner of your eye you spot him\n",
    "Shia LaBeouf\n",
    "\n",
    "He's following you, about 30 feet back\n",
    "He gets down on all fours and breaks into a sprint\n",
    "He's gaining on you\n",
    "Shia LaBeouf\n",
    "\n",
    "You're looking for you car but you're all turned around\n",
    "He's almost upon you now\n",
    "And you can see there's blood on his face\n",
    "My God, there's blood everywhere!\n",
    "\n",
    "Running for you life (from Shia LaBeouf)\n",
    "He's brandishing a knife (it's Shia LaBeouf)\n",
    "Lurking in the shadows\n",
    "Hollywood superstar Shia LaBeouf\n",
    "\n",
    "Living in the woods (Shia LaBeouf)\n",
    "Killing for sport (Shia LaBeouf)\n",
    "Eating all the bodies\n",
    "Actual cannibal Shia LaBeouf\"\"\"\n",
    "\n",
    "emoji_sequence = emojify(story=story)\n",
    "print(emoji_sequence.emoji_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d27890",
   "metadata": {},
   "outputs": [],
   "source": [
    "translate = dspy.Predict(\"string -> italian\")\n",
    "translation = translate(string=story)\n",
    "print(translation.italian)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e506541",
   "metadata": {},
   "source": [
    "### Single-shot predictors\n",
    "\n",
    "There's `Predict`, `ChainOfThought`, and `ChainOfThoughtWithHint` as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9a0abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "find_time_complexity = dspy.ChainOfThought(\"function -> time_complexity\")\n",
    "\n",
    "def fibonacci(n):\n",
    "    if n <= 1:\n",
    "        return n\n",
    "    else:\n",
    "        return fibonacci(n-1) + fibonacci(n-2)\n",
    "    \n",
    "complexity = find_time_complexity(function=fibonacci)\n",
    "print(complexity.completions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2146abd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cot_hint = dspy.ChainOfThoughtWithHint(\"question -> answer: float\")\n",
    "prediction = cot_hint(question=\"What is 16 x 17?\", hint=\"16x10=160 and 16x7=112\")  \n",
    "print(prediction.reasoning)\n",
    "print(\"----\")\n",
    "print(prediction.answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060bec9d",
   "metadata": {},
   "source": [
    "### Multi-shot Predictors\n",
    "\n",
    "Some built-in Modules use multiple LLM calls and tools to iteratively improve responses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dcbfd6f",
   "metadata": {},
   "source": [
    "`ReAct`: implements a *ReAct* agent pattern: the LLM alternates between thinking and calling user-supplied tooks, and stops when it fills the Signature. Used for search-and-answer agents, code-execution helpers, custom tool use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726249ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ReAct tool counts number of letter occurances in a string\n",
    "def count_letters(string: str) -> dict:\n",
    "    counts = {}\n",
    "    for letter in string:\n",
    "        if letter.isalpha():\n",
    "            counts[letter] = counts.get(letter, 0) + 1\n",
    "    return counts\n",
    "\n",
    "question_answerer = dspy.ReAct(\"question -> answer\",tools=[count_letters],max_iters=3)\n",
    "\n",
    "print(question_answerer(question=\"How many R's in the word strawberry?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b250161",
   "metadata": {},
   "source": [
    "`ProgramOfThought`: ask LLM to write a python program, executes it, then passes result back into the answer. \n",
    "\n",
    "It relies on `Deno`, a code runtime for lightweight scripts, which needs to be installed using:\n",
    "\n",
    "```bash\n",
    "brew install deno\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84376233",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dspy import PythonInterpreter\n",
    "\n",
    "#test that the Python interpreter works\n",
    "print(PythonInterpreter()(\"print('Hello World!')\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62ff7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pot = dspy.ProgramOfThought(\"question -> answer: float\", max_iters=5)\n",
    "\n",
    "code_gen = pot.code_generate(question=\"what is 5234 times 5324?\")\n",
    "#adding `.code_generate` to the end makes that the code doesn't execute. it just generates and returns the code.\n",
    "print(code_gen,\"=\"*15)\n",
    "\n",
    "\n",
    "result = pot(question=\"what is 5234 times 5324?\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14c8e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_2 = pot(question=\"what is 5234 times 5324?\")\n",
    "result_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7758ba01",
   "metadata": {},
   "outputs": [],
   "source": [
    "pot_math = dspy.ProgramOfThought(\"question -> answer: float\", max_iters=5).code_generate\n",
    "result = pot_math(question=\"What is the  third root of 963261?\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e76ea93",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_attempt = pot_math(question=\"what is the eigth root of 52876533252\")  # raw string\n",
    "print(code_attempt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e41b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "dspy.inspect_history(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d5da93",
   "metadata": {},
   "source": [
    "`MultiChainComparison`: Spins up `M` separate `ChainOfThought` traces, asks the LLM to vote-critique, and returns the best. Fastest way to logarithmically scale intelligence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d99e725",
   "metadata": {},
   "source": [
    "### Your Own Modules and Signatures\n",
    "\n",
    "Starting from the built-in ones, you can construct your own modules that include multiple LLM calls and complicated flows.\n",
    "\n",
    "Custom signatures work similarly. You can define multiple `InputField()` and `OutputField()`'s.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bed707",
   "metadata": {},
   "outputs": [],
   "source": [
    "#first, we'll tell it our birthday\n",
    "#and it figures out our sign\n",
    "class ZodiacSignature(dspy.Signature):\n",
    "    birth_day = dspy.InputField()\n",
    "    sign= dspy.OutputField(desc=\"Aries, Taurus, …, Pisces\")\n",
    "\n",
    "\n",
    "#then it creates a horoscope.\n",
    "class HoroscopeSignature(dspy.Signature):\n",
    "    sign= dspy.InputField(desc='Zodiac sign')\n",
    "    current_date= dspy.InputField(desc='In YYYY-MM-DD format')\n",
    "    horoscope= dspy.OutputField(desc=\"One-paragraph horoscope\")\n",
    "    lucky_numbers= dspy.OutputField(desc=\"Comma-separated lucky numbers\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0ca3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "\n",
    "\n",
    "class HoroscopeFromBirthday(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.predict_sign = dspy.Predict(ZodiacSignature)\n",
    "        self.create_horoscope=dspy.ChainOfThought(HoroscopeSignature)\n",
    "\n",
    "    def forward(self, birth_day:str):\n",
    "        #get the zodiac sign\n",
    "        sign_pred = self.predict_sign(birth_day=birth_day)\n",
    "        sign = sign_pred.sign\n",
    "        #create the horoscope\n",
    "        today = date.today()\n",
    "        horo_pred = self.create_horoscope(sign=sign,current_date=today)\n",
    "\n",
    "\n",
    "\n",
    "        #Prediction acts as the return type. A dictionary wrapper\n",
    "        return dspy.Prediction(\n",
    "            sign = sign,\n",
    "            horoscope_reasoning = horo_pred.reasoning,\n",
    "            horoscope = horo_pred.horoscope,\n",
    "            lucky_numbers = horo_pred.lucky_numbers\n",
    "        )\n",
    "\n",
    "\n",
    "zodiac_finder=HoroscopeFromBirthday()\n",
    "text = \"I was born on december 25, 2000\"\n",
    "print('Input:', text)\n",
    "print(zodiac_finder(birth_day=text))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75ff605",
   "metadata": {},
   "source": [
    "## Complex Module Example: Story Lab\n",
    "\n",
    "You give it a story scenario/genre and it will work through the idea:\n",
    "- first, it calls `FindInspo`, which comes up with a few catchy ideas.\n",
    "- then it drafts the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee49318",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FindInspo(dspy.Signature):\n",
    "    topic   = dspy.InputField()\n",
    "    blurbs  = dspy.OutputField(format=list, desc=\"3-5 catchy micro-blurbs\")\n",
    "\n",
    "class DraftPlot(dspy.Signature):\n",
    "    topic   = dspy.InputField()\n",
    "    blurbs  = dspy.InputField(format=list)\n",
    "    outline = dspy.OutputField(desc=\"bullet outline of the plot\")\n",
    "\n",
    "class BuildQuiz(dspy.Signature):\n",
    "    story      = dspy.InputField()\n",
    "    questions  = dspy.OutputField(\n",
    "        format=list,\n",
    "        desc=\"list of (Q, choices:list, correct:str) tuples\")\n",
    "\n",
    "class TeaseTweet(dspy.Signature):\n",
    "    story = dspy.InputField()\n",
    "    tweet = dspy.OutputField(desc=\"≤280-char teaser\")\n",
    "\n",
    "\n",
    "# ── 2. Custom module (3 distinct DSPy modules) ───────────────────\n",
    "class StoryPuzzleLab(dspy.Module):\n",
    "    \"\"\"\n",
    "    Modules used →\n",
    "      ① ChainOfThought         – inspirations & quiz\n",
    "      ② ChainOfThoughtWithHint – plot expansion\n",
    "      ③ ProgramOfThought       – code-driven puzzle generation\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.inspirer = dspy.ChainOfThought(FindInspo, n=1)\n",
    "        self.plotter  = dspy.ChainOfThoughtWithHint(DraftPlot)\n",
    "        self.quizzer  = dspy.ChainOfThought(BuildQuiz)\n",
    "        self.teaser   = dspy.ChainOfThought(TeaseTweet, max_len=70)  # ≈ tweet\n",
    "\n",
    "    def forward(self, topic: str):\n",
    "        blurbs   = self.inspirer(topic=topic).blurbs\n",
    "        outline  = self.plotter(topic=topic, blurbs=blurbs).outline\n",
    "        quiz     = self.quizzer(story=outline).questions\n",
    "        tweet    = self.teaser(story=outline).tweet\n",
    "\n",
    "        return dict(outline=outline, quiz=quiz, tweet=tweet, inspo=blurbs)\n",
    "\n",
    "\n",
    "\n",
    "lab = StoryPuzzleLab()\n",
    "res = lab(\"Lost temple, steam-age explorers\")\n",
    "print(\"\\n— INSPIRATION —\\n\", res[\"inspo\"])\n",
    "print(\"\\n— STORY —\\n\",res[\"outline\"])\n",
    "print(\"\\n— QUIZ —\\n\",res['quiz'])\n",
    "print(\"\\n— TWEET —\\n\", res[\"tweet\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a7dfc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf46923",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(res['quiz'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aeb2384",
   "metadata": {},
   "source": [
    "## So What?: Optimizers\n",
    "\n",
    "The syntax is nice and simple and whatever but what's so special about DSPy?\n",
    "\n",
    "Well notice how we haven't really defined individual *prompts*? Instead we've been defining Signatures that convey some amount of prompt information. On the backend, Signatures are parsed and converted into one of many basic boilerplate prompts.  *Optimizers* act as ways to iteratively improved those boiletplate prompts.  \n",
    "\n",
    "You define a metric associated with the Module you've constructed, you run a couple data samples through the system, then the Optimizer comes in and tweaks the prompts based on the failure modes it's picked up on.  \n",
    "\n",
    "There's a ton of different Optimizers out there that each try to modify the prompts in different ways:\n",
    "- `BootstrapFewShot` creates few-shot demonstrations\n",
    "- `MIPROv2` and `COPRO` use Bayesian search to propose better natural language instruction. \n",
    "- `BootstrapFinetune` can be used with smaller LLMs to distill the prompts into weight updates\n",
    "\n",
    "Each Optimizer accepts two arguments: \n",
    "- a `Module`\n",
    "- a metric function that returns a float\n",
    "- train/validation data: 10-300 `Examples`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4f89fe",
   "metadata": {},
   "source": [
    "This example is for sentiment analysis, a pretty mundane task nowadays, but there's tons of available data for it.  For data we're using the Stanford Sentiment Treebank, a collection of single sentence rotton tomatoes reviews that are labelled as either positive or negative. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce02afed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example\n",
      "{'idx': 6, 'sentence': 'demonstrates that the director of such hollywood blockbusters as patriot games can still turn out a small , personal film with an emotional wallop . ', 'label': 1}\n"
     ]
    }
   ],
   "source": [
    "from dspy.teleprompt import BootstrapFewShot\n",
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "#construct module\n",
    "sentiment = dspy.Predict(\"text -> label\")\n",
    "\n",
    "ds = load_dataset(\"sst2\", split=\"train[:20]\")\n",
    "print(\"Example\")\n",
    "print(ds[6])\n",
    "\n",
    "\n",
    "\n",
    "trainset = [\n",
    "    dspy.Example(text=ex[\"sentence\"],\n",
    "                 label=\"positive\" if ex[\"label\"] else \"negative\").with_inputs(\"text\")\n",
    "    for ex in ds\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45657b6a",
   "metadata": {},
   "source": [
    "Next we have to define our metric function, which captures some sort of validation on the task we're trying to complete. In this case it's pretty trivial: does the Module return the correct label?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "64e8d92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def em(example, pred, **_): \n",
    "    return int(example.label == pred.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e918937",
   "metadata": {},
   "source": [
    "For our first round of optimizations we're using BootstrapFewShot. This optimizer adds `k` fewshot examples to the prompt.  Essentially it automates the process of picking the examples that work the best.\n",
    "\n",
    "\n",
    "\n",
    "For tasks with small token counts you can set the number of examples pretty high. For high token count things that gets a little trickier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "743f980e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]2025/05/18 17:10:17 ERROR dspy.teleprompt.bootstrap: Failed to run or to evaluate example Example({'text': 'hide new secretions from the parental units ', 'label': 'negative'}) (input_keys=None) with <function em at 0x121b39260> due to Inputs have not been set for this example. Use `example.with_inputs()` to set them..\n",
      "2025/05/18 17:10:17 ERROR dspy.teleprompt.bootstrap: Failed to run or to evaluate example Example({'text': 'contains no wit , only labored gags ', 'label': 'negative'}) (input_keys=None) with <function em at 0x121b39260> due to Inputs have not been set for this example. Use `example.with_inputs()` to set them..\n",
      "2025/05/18 17:10:17 ERROR dspy.teleprompt.bootstrap: Failed to run or to evaluate example Example({'text': 'that loves its characters and communicates something rather beautiful about human nature ', 'label': 'positive'}) (input_keys=None) with <function em at 0x121b39260> due to Inputs have not been set for this example. Use `example.with_inputs()` to set them..\n",
      "2025/05/18 17:10:17 ERROR dspy.teleprompt.bootstrap: Failed to run or to evaluate example Example({'text': 'remains utterly satisfied to remain the same throughout ', 'label': 'negative'}) (input_keys=None) with <function em at 0x121b39260> due to Inputs have not been set for this example. Use `example.with_inputs()` to set them..\n",
      " 20%|██        | 4/20 [00:00<00:00, 819.68it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Inputs have not been set for this example. Use `example.with_inputs()` to set them.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m opt = BootstrapFewShot(metric=em,\n\u001b[32m      2\u001b[39m                        max_labeled_demos=\u001b[32m4\u001b[39m,\n\u001b[32m      3\u001b[39m                        max_bootstrapped_demos=\u001b[32m4\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m sentiment_clf = \u001b[43mopt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentiment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrainset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(sentiment_clf(\u001b[33m\"\u001b[39m\u001b[33mIt was a delightful movie!\u001b[39m\u001b[33m\"\u001b[39m).label)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repos/personal/obsidian-llm-tool-use/.venv/lib/python3.12/site-packages/dspy/teleprompt/bootstrap.py:83\u001b[39m, in \u001b[36mBootstrapFewShot.compile\u001b[39m\u001b[34m(self, student, teacher, trainset)\u001b[39m\n\u001b[32m     81\u001b[39m \u001b[38;5;28mself\u001b[39m._prepare_student_and_teacher(student, teacher)\n\u001b[32m     82\u001b[39m \u001b[38;5;28mself\u001b[39m._prepare_predictor_mappings()\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_bootstrap\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     85\u001b[39m \u001b[38;5;28mself\u001b[39m.student = \u001b[38;5;28mself\u001b[39m._train()\n\u001b[32m     86\u001b[39m \u001b[38;5;28mself\u001b[39m.student._compiled = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repos/personal/obsidian-llm-tool-use/.venv/lib/python3.12/site-packages/dspy/teleprompt/bootstrap.py:158\u001b[39m, in \u001b[36mBootstrapFewShot._bootstrap\u001b[39m\u001b[34m(self, max_bootstraps)\u001b[39m\n\u001b[32m    155\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m round_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.max_rounds):\n\u001b[32m    156\u001b[39m     bootstrap_attempts += \u001b[32m1\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m158\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_bootstrap_one_example\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mround_idx\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    159\u001b[39m         bootstrapped[example_idx] = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    160\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repos/personal/obsidian-llm-tool-use/.venv/lib/python3.12/site-packages/dspy/teleprompt/bootstrap.py:214\u001b[39m, in \u001b[36mBootstrapFewShot._bootstrap_one_example\u001b[39m\u001b[34m(self, example, round_idx)\u001b[39m\n\u001b[32m    212\u001b[39m         current_error_count = \u001b[38;5;28mself\u001b[39m.error_count\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m current_error_count >= \u001b[38;5;28mself\u001b[39m.max_errors:\n\u001b[32m--> \u001b[39m\u001b[32m214\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    215\u001b[39m     logger.error(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to run or to evaluate example \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexample\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.metric\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m due to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m success:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repos/personal/obsidian-llm-tool-use/.venv/lib/python3.12/site-packages/dspy/teleprompt/bootstrap.py:194\u001b[39m, in \u001b[36mBootstrapFewShot._bootstrap_one_example\u001b[39m\u001b[34m(self, example, round_idx)\u001b[39m\n\u001b[32m    191\u001b[39m     predictor_cache[name] = predictor.demos\n\u001b[32m    192\u001b[39m     predictor.demos = [x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m predictor.demos \u001b[38;5;28;01mif\u001b[39;00m x != example]\n\u001b[32m--> \u001b[39m\u001b[32m194\u001b[39m prediction = teacher(**\u001b[43mexample\u001b[49m\u001b[43m.\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    195\u001b[39m trace = dspy.settings.trace\n\u001b[32m    197\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m name, predictor \u001b[38;5;129;01min\u001b[39;00m teacher.named_predictors():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repos/personal/obsidian-llm-tool-use/.venv/lib/python3.12/site-packages/dspy/primitives/example.py:80\u001b[39m, in \u001b[36mExample.inputs\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     78\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minputs\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m     79\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._input_keys \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m80\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mInputs have not been set for this example. Use `example.with_inputs()` to set them.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     82\u001b[39m     \u001b[38;5;66;03m# return items that are in input_keys\u001b[39;00m\n\u001b[32m     83\u001b[39m     d = {key: \u001b[38;5;28mself\u001b[39m._store[key] \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._store \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._input_keys}\n",
      "\u001b[31mValueError\u001b[39m: Inputs have not been set for this example. Use `example.with_inputs()` to set them."
     ]
    }
   ],
   "source": [
    "opt = BootstrapFewShot(metric=em,\n",
    "                       max_labeled_demos=4,\n",
    "                       max_bootstrapped_demos=4)\n",
    "sentiment_clf = opt.compile(sentiment, trainset=trainset)\n",
    "\n",
    "\n",
    "print(sentiment_clf(\"It was a delightful movie!\").label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ee7082",
   "metadata": {},
   "source": [
    "Optimizers can be saved to json using `save()` and autologged to MLFlow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56363a80",
   "metadata": {},
   "source": [
    "## Different Optimizer Methods\n",
    "\n",
    "## Going Larger: Programs\n",
    "\n",
    "## Logging LLM calls for debugging\n",
    "\n",
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef973678",
   "metadata": {},
   "source": [
    "# Appendix\n",
    "\n",
    "### Bayesian Search\n",
    "Also called Bayesian optimization. It's a strategy for searching through a large parameter-space with only a small amount of traversals are allowed.  It tries to balance exploration with exploitation\n",
    "\n",
    "1. Start with some given prior.\n",
    "2. Try a few prompts and record their scores\n",
    "3. Fit a surrogate model: try to cheaply model the relationship between instruction -> expected score.\n",
    "4. Use the surrogate to identify potential new instruction candidates.\n",
    "5. Evaluate, update surrogate, repeat.\n",
    "\n",
    "It's basically a cheap and dirty way to get something functioning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8ae040",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
