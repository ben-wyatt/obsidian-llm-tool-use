{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a865a950",
   "metadata": {},
   "source": [
    "Links\n",
    "- [DSPy Documentation](https://dspy.ai/#__tabbed_1_4)\n",
    "\n",
    "\n",
    "Double Saved to `obsidian-llm-tool-use` Github repo and my personal note vault in obsidian via:\n",
    "```bash\n",
    "jupytext --to markdown dspy_modules/intro_to_dspy.ipynb -o ~/Obsidian/Notes\\ Vault/intro_to_dspy.md\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09674048",
   "metadata": {},
   "source": [
    "First, import the package and setup your llm calling configuration. For this, we'll be using ollama.\n",
    "\n",
    "Make sure to spin up your ollama server using\n",
    "```bash\n",
    "ollama start\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5efa3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "lm = dspy.LM('openai/qwen2.5:7b-instruct-q4_K_M', api_base='http://localhost:11434/v1', api_key='')\n",
    "dspy.configure(lm=lm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e980b6f0",
   "metadata": {},
   "source": [
    "Lets do the basic prompt-response: just use the `lm` as a function!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba8b1023",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Sure, this certainly seems like a test! How can I help you with it? Whether it's a language comprehension test, a creativity challenge, or something else entirely, feel free to provide more details so I can assist you better.\"]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm(\"Say this is a test!\", temperature=0.7)  # => ['This is a test!']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78536af",
   "metadata": {},
   "source": [
    "Super compact syntax.\n",
    "\n",
    "You could just use this as a nice way to make your LLM calls a bit more pythonic.\n",
    "\n",
    "You can also send using the chat completions formatting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf846a5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Of course! This is definitely a test. How can I help you with it? Whether you're looking to practice language skills, need some questions answered, or just want to see how things work, feel free to let me know what you'd like to do!\"]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm(messages=[{\"role\": \"user\", \"content\": \"Say this is a test!\"}])  # => ['This is a test!']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555bb837",
   "metadata": {},
   "source": [
    "Ok now to the first main topic:\n",
    "\n",
    "## Modules\n",
    "\n",
    "Modules help you describe AI behavior as *code*. not *strings*.\n",
    "\n",
    "You specify a *Signature*: a string that defines an action via inputs and outputs behavior: `\"question -> answer: float\"`\n",
    "\n",
    "Then you select a *Module* to assign a strategy for invoking the LLM. `Predict` is the simplest one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0fa9660e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completions(\n",
      "    answer=[2.0]\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "solve_math = dspy.Predict(\"question -> answer: float\")\n",
    "result = solve_math(question=\"What is 1 + 1?\")\n",
    "print(result.completions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225e99f1",
   "metadata": {},
   "source": [
    "A Module:\n",
    "- wraps a signature.\n",
    "- is callable\n",
    "- carries \"learnable parameters\" that DSPy can run optimization on.\n",
    "- composes: modules call other modules, can be stored as `json`, or be nested inside larger `dspy.Program` graphs.\n",
    "- persists: `module.save()`/`load()` for controlling state.\n",
    "\n",
    "\n",
    "There's a few really powerful primative ones already implemented, like `dspy.ChainOfThought`. It automatically:\n",
    "1. Inserts an instruction telling the LLM to show its reasoning.\n",
    "2. Adds an implicit extra output field called `reasoning`.\n",
    "3. Returns both the reasoning and the final answer, while still respecting the original signature.\n",
    "\n",
    "So that's why it won't be very good for:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d3e7d7bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completions(\n",
      "    reasoning=['To find the third root of 963261, we need to calculate 963261^(1/3).'],\n",
      "    answer=[45.0]\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "result = solve_math(question=\"What is the third root of 963261?\")\n",
    "print(result.completions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6218c0e8",
   "metadata": {},
   "source": [
    "But you can get pretty creative with the signatures.  LLM act as this universal function approximator written via English.  Modules try to shape that approximator into a math function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce8591a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyboard\n"
     ]
    }
   ],
   "source": [
    "solve_riddle = dspy.Predict(\"riddle -> answer\")\n",
    "print(solve_riddle(riddle=\"What has keys but can't open locks?\").answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff51c38",
   "metadata": {},
   "source": [
    "In your *Signature* you can list multiple fields: `\"context: list[str], question -> answer\"` or omit the types if they're strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa95f473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completions(\n",
      "    emoji_sequence=['🌳📱🏃\\u200d♂️👀🧱🔥🔪 manhuntsurvivorHunterShiaLaBeoufwoods CannibalShiaLaBeouf']\n",
      ")\n",
      "🌳📱🏃‍♂️👀🧱🔥🔪 manhuntsurvivorHunterShiaLaBeoufwoods CannibalShiaLaBeouf\n"
     ]
    }
   ],
   "source": [
    "emojify = dspy.Predict(\"story -> emoji_sequence\")\n",
    "\n",
    "story=\"\"\"You're walking in the woods\n",
    "There's no one around and your phone is dead\n",
    "Out of the corner of your eye you spot him\n",
    "Shia LaBeouf\n",
    "\n",
    "He's following you, about 30 feet back\n",
    "He gets down on all fours and breaks into a sprint\n",
    "He's gaining on you\n",
    "Shia LaBeouf\n",
    "\n",
    "You're looking for you car but you're all turned around\n",
    "He's almost upon you now\n",
    "And you can see there's blood on his face\n",
    "My God, there's blood everywhere!\n",
    "\n",
    "Running for you life (from Shia LaBeouf)\n",
    "He's brandishing a knife (it's Shia LaBeouf)\n",
    "Lurking in the shadows\n",
    "Hollywood superstar Shia LaBeouf\n",
    "\n",
    "Living in the woods (Shia LaBeouf)\n",
    "Killing for sport (Shia LaBeouf)\n",
    "Eating all the bodies\n",
    "Actual cannibal Shia LaBeouf\"\"\"\n",
    "\n",
    "emoji_sequence = emojify(story=story)\n",
    "print(emoji_sequence.emoji_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d27890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stai camminando nel bosco\n",
      "Non c'è nessuno intorno e il tuo cellulare non funziona\n",
      "Dalla parte del tuo occhio destro lo vedi\n",
      "Shia LaBeouf\n",
      "\n",
      "Lo sta seguendo, a circa 30 piedi di distanza\n",
      "Si mette in quattro zampe e scatta in corsa\n",
      "Sta guadagnando terreno\n",
      "Shia LaBeouf\n",
      "\n",
      "Cercavi la tua macchina ma ti sei girato tutto intorno\n",
      "Ora è quasi sopra di te\n",
      "E puoi vedere che c'è sangue sul suo viso\n",
      "Dio mio, c'è sangue dappertutto!\n",
      "\n",
      "Correndo per la tua vita (da Shia LaBeouf)\n",
      "Sta brandendo un coltello (è Shia LaBeouf)\n",
      "Si aggira nelle ombre\n",
      "Superstite hollywoodiano Shia LaBeouf\n",
      "\n",
      "Vivere nel bosco (Shia LaBeouf)\n",
      "Uccidendo a sangue caldo (Shia LaBeouf)\n",
      "Mangiando tutti i corpi\n",
      "Cannibale reale Shia LaBeouf\n"
     ]
    }
   ],
   "source": [
    "translate = dspy.Predict(\"string -> italian\")\n",
    "translation = translate(string=story)\n",
    "print(translation.italian)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e506541",
   "metadata": {},
   "source": [
    "### Single-shot predictors\n",
    "\n",
    "There's `Predict`, `ChainOfThought`, and `ChainOfThoughtWithHint` as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9a0abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completions(\n",
      "    reasoning=[\"The Fibonacci function is typically implemented using recursion or iteration. In this case, since no specific implementation details are provided, we will consider a basic recursive approach which has an exponential time complexity due to the repeated calculations of the same subproblems.\\n\\nFor the iterative approach, it would have a linear time complexity. However, without knowing the exact implementation, we'll assume the worst-case scenario for simplicity.\"],\n",
      "    time_complexity=['O(2^n)']\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "find_time_complexity = dspy.ChainOfThought(\"function -> time_complexity\")\n",
    "\n",
    "def fibonacci(n):\n",
    "    if n <= 1:\n",
    "        return n\n",
    "    else:\n",
    "        return fibonacci(n-1) + fibonacci(n-2)\n",
    "    \n",
    "complexity = find_time_complexity(function=fibonacci)\n",
    "print(complexity.completions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2146abd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We can use the distributive property of multiplication over addition to solve this problem. The hint suggests breaking down 17 into 10 + 7, so we have:\n",
      "\n",
      "\\[ 16 \\times 17 = 16 \\times (10 + 7) = (16 \\times 10) + (16 \\times 7) \\]\n",
      "\n",
      "Given that \\(16 \\times 10 = 160\\) and \\(16 \\times 7 = 112\\), we can add these two results together:\n",
      "\n",
      "\\[ 160 + 112 = 272 \\]\n",
      "\n",
      "Therefore, the answer is 272.\n",
      "----\n",
      "272.0\n"
     ]
    }
   ],
   "source": [
    "cot_hint = dspy.ChainOfThoughtWithHint(\"question -> answer: float\")\n",
    "prediction = cot_hint(question=\"What is 16 x 17?\", hint=\"16x10=160 and 16x7=112\")  \n",
    "print(prediction.reasoning)\n",
    "print(\"----\")\n",
    "print(prediction.answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060bec9d",
   "metadata": {},
   "source": [
    "### Multi-shot Predictors\n",
    "\n",
    "Some built-in Modules use multiple LLM calls and tools to iteratively improve responses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dcbfd6f",
   "metadata": {},
   "source": [
    "`ReAct`: implements a *ReAct* agent pattern: the LLM alternates between thinking and calling user-supplied tooks, and stops when it fills the Signature. Used for search-and-answer agents, code-execution helpers, custom tool use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "726249ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction(\n",
      "    trajectory={'thought_0': 'To find out how many R\\'s are in the word \"strawberry\", I can use the count_letters tool.', 'tool_name_0': 'count_letters', 'tool_args_0': {'string': 'strawberry'}, 'observation_0': {'s': 1, 't': 1, 'r': 3, 'a': 1, 'w': 1, 'b': 1, 'e': 1, 'y': 1}, 'thought_1': 'The count_letters tool returned that the word \"strawberry\" contains 3 \\'r\\'s. Since I have all the information needed to answer the question, I can now finish.', 'tool_name_1': 'finish', 'tool_args_1': {}, 'observation_1': 'Completed.'},\n",
      "    reasoning='To determine how many R\\'s are in the word \"strawberry\", I used a tool to count each letter. The result showed that there are 3 \\'r\\'s.',\n",
      "    answer=\"There are 3 R's in the word strawberry.\"\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# ReAct tool counts number of letter occurances in a string\n",
    "def count_letters(string: str) -> dict:\n",
    "    counts = {}\n",
    "    for letter in string:\n",
    "        if letter.isalpha():\n",
    "            counts[letter] = counts.get(letter, 0) + 1\n",
    "    return counts\n",
    "\n",
    "question_answerer = dspy.ReAct(\"question -> answer\",tools=[count_letters],max_iters=3)\n",
    "\n",
    "print(question_answerer(question=\"How many R's in the word strawberry?\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b250161",
   "metadata": {},
   "source": [
    "`ProgramOfThought`: ask LLM to write a python program, executes it, then passes result back into the answer. \n",
    "\n",
    "It relies on `Deno`, which needs to be installed using:\n",
    "\n",
    "```bash\n",
    "brew install deno\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7758ba01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/12 20:22:39 ERROR dspy.predict.program_of_thought: Error in code execution: Invalid Python syntax. message: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m pot_math = dspy.ProgramOfThought(\u001b[33m\"\u001b[39m\u001b[33mquestion -> answer\u001b[39m\u001b[33m\"\u001b[39m, max_iters=\u001b[32m3\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mpot_math\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mWhat is the third root of 963261?\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m.answer)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repos/personal/obsidian-llm-tool-use/.venv/lib/python3.12/site-packages/dspy/utils/callback.py:326\u001b[39m, in \u001b[36mwith_callbacks.<locals>.sync_wrapper\u001b[39m\u001b[34m(instance, *args, **kwargs)\u001b[39m\n\u001b[32m    324\u001b[39m callbacks = _get_active_callbacks(instance)\n\u001b[32m    325\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m callbacks:\n\u001b[32m--> \u001b[39m\u001b[32m326\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    328\u001b[39m call_id = uuid.uuid4().hex\n\u001b[32m    330\u001b[39m _execute_start_callbacks(instance, fn, call_id, callbacks, args, kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repos/personal/obsidian-llm-tool-use/.venv/lib/python3.12/site-packages/dspy/primitives/program.py:32\u001b[39m, in \u001b[36mModule.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     29\u001b[39m         output.set_lm_usage(usage_tracker.get_total_tokens())\n\u001b[32m     30\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m output\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repos/personal/obsidian-llm-tool-use/.venv/lib/python3.12/site-packages/dspy/predict/program_of_thought.py:190\u001b[39m, in \u001b[36mProgramOfThought.forward\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m    188\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMax hops reached. Failed to run ProgramOfThought: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    189\u001b[39m input_kwargs.update({\u001b[33m\"\u001b[39m\u001b[33mprevious_code\u001b[39m\u001b[33m\"\u001b[39m: code, \u001b[33m\"\u001b[39m\u001b[33merror\u001b[39m\u001b[33m\"\u001b[39m: error})\n\u001b[32m--> \u001b[39m\u001b[32m190\u001b[39m code_data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcode_regenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minput_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    191\u001b[39m code, error = \u001b[38;5;28mself\u001b[39m._parse_code(code_data)\n\u001b[32m    192\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m error:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repos/personal/obsidian-llm-tool-use/.venv/lib/python3.12/site-packages/dspy/utils/callback.py:326\u001b[39m, in \u001b[36mwith_callbacks.<locals>.sync_wrapper\u001b[39m\u001b[34m(instance, *args, **kwargs)\u001b[39m\n\u001b[32m    324\u001b[39m callbacks = _get_active_callbacks(instance)\n\u001b[32m    325\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m callbacks:\n\u001b[32m--> \u001b[39m\u001b[32m326\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    328\u001b[39m call_id = uuid.uuid4().hex\n\u001b[32m    330\u001b[39m _execute_start_callbacks(instance, fn, call_id, callbacks, args, kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repos/personal/obsidian-llm-tool-use/.venv/lib/python3.12/site-packages/dspy/primitives/program.py:32\u001b[39m, in \u001b[36mModule.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     29\u001b[39m         output.set_lm_usage(usage_tracker.get_total_tokens())\n\u001b[32m     30\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m output\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repos/personal/obsidian-llm-tool-use/.venv/lib/python3.12/site-packages/dspy/predict/chain_of_thought.py:38\u001b[39m, in \u001b[36mChainOfThought.forward\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, **kwargs):\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repos/personal/obsidian-llm-tool-use/.venv/lib/python3.12/site-packages/dspy/utils/callback.py:326\u001b[39m, in \u001b[36mwith_callbacks.<locals>.sync_wrapper\u001b[39m\u001b[34m(instance, *args, **kwargs)\u001b[39m\n\u001b[32m    324\u001b[39m callbacks = _get_active_callbacks(instance)\n\u001b[32m    325\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m callbacks:\n\u001b[32m--> \u001b[39m\u001b[32m326\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    328\u001b[39m call_id = uuid.uuid4().hex\n\u001b[32m    330\u001b[39m _execute_start_callbacks(instance, fn, call_id, callbacks, args, kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repos/personal/obsidian-llm-tool-use/.venv/lib/python3.12/site-packages/dspy/predict/predict.py:76\u001b[39m, in \u001b[36mPredict.__call__\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m     74\u001b[39m \u001b[38;5;129m@with_callbacks\u001b[39m\n\u001b[32m     75\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, **kwargs):\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repos/personal/obsidian-llm-tool-use/.venv/lib/python3.12/site-packages/dspy/predict/predict.py:132\u001b[39m, in \u001b[36mPredict.forward\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    131\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m settings.context(send_stream=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m132\u001b[39m         completions = \u001b[43madapter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlm_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignature\u001b[49m\u001b[43m=\u001b[49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdemos\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdemos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    134\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_postprocess(completions, signature, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repos/personal/obsidian-llm-tool-use/.venv/lib/python3.12/site-packages/dspy/adapters/chat_adapter.py:41\u001b[39m, in \u001b[36mChatAdapter.__call__\u001b[39m\u001b[34m(self, lm, lm_kwargs, signature, demos, inputs)\u001b[39m\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\n\u001b[32m     33\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     34\u001b[39m     lm: LM,\n\u001b[32m   (...)\u001b[39m\u001b[32m     38\u001b[39m     inputs: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[32m     39\u001b[39m ) -> \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[32m     40\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlm_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdemos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     42\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     43\u001b[39m         \u001b[38;5;66;03m# fallback to JSONAdapter\u001b[39;00m\n\u001b[32m     44\u001b[39m         \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdspy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01madapters\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mjson_adapter\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m JSONAdapter\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repos/personal/obsidian-llm-tool-use/.venv/lib/python3.12/site-packages/dspy/adapters/base.py:51\u001b[39m, in \u001b[36mAdapter.__call__\u001b[39m\u001b[34m(self, lm, lm_kwargs, signature, demos, inputs)\u001b[39m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\n\u001b[32m     42\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     43\u001b[39m     lm: \u001b[33m\"\u001b[39m\u001b[33mLM\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     47\u001b[39m     inputs: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[32m     48\u001b[39m ) -> \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[32m     49\u001b[39m     inputs = \u001b[38;5;28mself\u001b[39m.format(signature, demos, inputs)\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m     outputs = \u001b[43mlm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mlm_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     52\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_post_process(outputs, signature)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repos/personal/obsidian-llm-tool-use/.venv/lib/python3.12/site-packages/dspy/utils/callback.py:326\u001b[39m, in \u001b[36mwith_callbacks.<locals>.sync_wrapper\u001b[39m\u001b[34m(instance, *args, **kwargs)\u001b[39m\n\u001b[32m    324\u001b[39m callbacks = _get_active_callbacks(instance)\n\u001b[32m    325\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m callbacks:\n\u001b[32m--> \u001b[39m\u001b[32m326\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    328\u001b[39m call_id = uuid.uuid4().hex\n\u001b[32m    330\u001b[39m _execute_start_callbacks(instance, fn, call_id, callbacks, args, kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repos/personal/obsidian-llm-tool-use/.venv/lib/python3.12/site-packages/dspy/clients/base_lm.py:89\u001b[39m, in \u001b[36mBaseLM.__call__\u001b[39m\u001b[34m(self, prompt, messages, **kwargs)\u001b[39m\n\u001b[32m     87\u001b[39m \u001b[38;5;129m@with_callbacks\u001b[39m\n\u001b[32m     88\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, prompt=\u001b[38;5;28;01mNone\u001b[39;00m, messages=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m---> \u001b[39m\u001b[32m89\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     90\u001b[39m     outputs = \u001b[38;5;28mself\u001b[39m._process_lm_response(response, prompt, messages, **kwargs)\n\u001b[32m     92\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repos/personal/obsidian-llm-tool-use/.venv/lib/python3.12/site-packages/dspy/clients/lm.py:107\u001b[39m, in \u001b[36mLM.forward\u001b[39m\u001b[34m(self, prompt, messages, **kwargs)\u001b[39m\n\u001b[32m    104\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cache_in_memory:\n\u001b[32m    105\u001b[39m     completion = cached_litellm_completion \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.model_type == \u001b[33m\"\u001b[39m\u001b[33mchat\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m cached_litellm_text_completion\n\u001b[32m--> \u001b[39m\u001b[32m107\u001b[39m     results = \u001b[43mcompletion\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    108\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    109\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnum_retries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnum_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    110\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    112\u001b[39m     completion = litellm_completion \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.model_type == \u001b[33m\"\u001b[39m\u001b[33mchat\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m litellm_text_completion\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repos/personal/obsidian-llm-tool-use/.venv/lib/python3.12/site-packages/dspy/clients/cache.py:224\u001b[39m, in \u001b[36mrequest_cache.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    221\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cached_result\n\u001b[32m    223\u001b[39m \u001b[38;5;66;03m# Otherwise, compute and store the result\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m224\u001b[39m result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    225\u001b[39m cache.put(modified_request, result)\n\u001b[32m    227\u001b[39m cache.ignored_args_for_cache_key = original_ignored_args_for_cache_key\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repos/personal/obsidian-llm-tool-use/.venv/lib/python3.12/site-packages/dspy/clients/lm.py:218\u001b[39m, in \u001b[36mcached_litellm_completion\u001b[39m\u001b[34m(request, num_retries)\u001b[39m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    216\u001b[39m     litellm_cache_args = {\u001b[33m\"\u001b[39m\u001b[33mno-cache\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mno-store\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m}\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlitellm_completion\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    220\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlitellm_cache_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    221\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_retries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    222\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repos/personal/obsidian-llm-tool-use/.venv/lib/python3.12/site-packages/dspy/clients/lm.py:240\u001b[39m, in \u001b[36mlitellm_completion\u001b[39m\u001b[34m(request, num_retries, cache)\u001b[39m\n\u001b[32m    236\u001b[39m caller_predict = dspy.settings.caller_predict\n\u001b[32m    237\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    238\u001b[39m     \u001b[38;5;66;03m# If `streamify` is not used, or if the exact predict doesn't need to be streamed,\u001b[39;00m\n\u001b[32m    239\u001b[39m     \u001b[38;5;66;03m# we can just return the completion without streaming.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m240\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlitellm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletion\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    241\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    242\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mretry_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    243\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    244\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    246\u001b[39m \u001b[38;5;66;03m# The stream is already opened, and will be closed by the caller.\u001b[39;00m\n\u001b[32m    247\u001b[39m stream = cast(MemoryObjectSendStream, stream)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repos/personal/obsidian-llm-tool-use/.venv/lib/python3.12/site-packages/litellm/utils.py:1133\u001b[39m, in \u001b[36mclient.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   1131\u001b[39m         print_verbose(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError while checking max token limit: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m   1132\u001b[39m \u001b[38;5;66;03m# MODEL CALL\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1133\u001b[39m result = \u001b[43moriginal_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1134\u001b[39m end_time = datetime.datetime.now()\n\u001b[32m   1135\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m kwargs[\u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repos/personal/obsidian-llm-tool-use/.venv/lib/python3.12/site-packages/litellm/main.py:1772\u001b[39m, in \u001b[36mcompletion\u001b[39m\u001b[34m(model, messages, timeout, temperature, top_p, n, stream, stream_options, stop, max_completion_tokens, max_tokens, modalities, prediction, audio, presence_penalty, frequency_penalty, logit_bias, user, reasoning_effort, response_format, seed, tools, tool_choice, logprobs, top_logprobs, parallel_tool_calls, deployment_id, extra_headers, functions, function_call, base_url, api_version, api_key, model_list, thinking, **kwargs)\u001b[39m\n\u001b[32m   1770\u001b[39m \u001b[38;5;66;03m## COMPLETION CALL\u001b[39;00m\n\u001b[32m   1771\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1772\u001b[39m     response = \u001b[43mopenai_chat_completions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletion\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1773\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1774\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1775\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1776\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_response\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_response\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1777\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprint_verbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_verbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1778\u001b[39m \u001b[43m        \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m=\u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1779\u001b[39m \u001b[43m        \u001b[49m\u001b[43mapi_base\u001b[49m\u001b[43m=\u001b[49m\u001b[43mapi_base\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1780\u001b[39m \u001b[43m        \u001b[49m\u001b[43macompletion\u001b[49m\u001b[43m=\u001b[49m\u001b[43macompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1781\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlogging_obj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlogging\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1782\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptional_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptional_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1783\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlitellm_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlitellm_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1784\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlogger_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlogger_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1785\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[32m   1786\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcustom_prompt_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcustom_prompt_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1787\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pass AsyncOpenAI, OpenAI client\u001b[39;49;00m\n\u001b[32m   1788\u001b[39m \u001b[43m        \u001b[49m\u001b[43morganization\u001b[49m\u001b[43m=\u001b[49m\u001b[43morganization\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1789\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcustom_llm_provider\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcustom_llm_provider\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1790\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1791\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1792\u001b[39m     \u001b[38;5;66;03m## LOGGING - log the original exception returned\u001b[39;00m\n\u001b[32m   1793\u001b[39m     logging.post_call(\n\u001b[32m   1794\u001b[39m         \u001b[38;5;28minput\u001b[39m=messages,\n\u001b[32m   1795\u001b[39m         api_key=api_key,\n\u001b[32m   1796\u001b[39m         original_response=\u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m   1797\u001b[39m         additional_args={\u001b[33m\"\u001b[39m\u001b[33mheaders\u001b[39m\u001b[33m\"\u001b[39m: headers},\n\u001b[32m   1798\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repos/personal/obsidian-llm-tool-use/.venv/lib/python3.12/site-packages/litellm/llms/openai/openai.py:652\u001b[39m, in \u001b[36mOpenAIChatCompletion.completion\u001b[39m\u001b[34m(self, model_response, timeout, optional_params, litellm_params, logging_obj, model, messages, print_verbose, api_key, api_base, api_version, dynamic_params, azure_ad_token, acompletion, logger_fn, headers, custom_prompt_dict, client, organization, custom_llm_provider, drop_params)\u001b[39m\n\u001b[32m    637\u001b[39m \u001b[38;5;66;03m## LOGGING\u001b[39;00m\n\u001b[32m    638\u001b[39m logging_obj.pre_call(\n\u001b[32m    639\u001b[39m     \u001b[38;5;28minput\u001b[39m=messages,\n\u001b[32m    640\u001b[39m     api_key=openai_client.api_key,\n\u001b[32m   (...)\u001b[39m\u001b[32m    646\u001b[39m     },\n\u001b[32m    647\u001b[39m )\n\u001b[32m    649\u001b[39m (\n\u001b[32m    650\u001b[39m     headers,\n\u001b[32m    651\u001b[39m     response,\n\u001b[32m--> \u001b[39m\u001b[32m652\u001b[39m ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmake_sync_openai_chat_completion_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    653\u001b[39m \u001b[43m    \u001b[49m\u001b[43mopenai_client\u001b[49m\u001b[43m=\u001b[49m\u001b[43mopenai_client\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    654\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    655\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    656\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlogging_obj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlogging_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    657\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    659\u001b[39m logging_obj.model_call_details[\u001b[33m\"\u001b[39m\u001b[33mresponse_headers\u001b[39m\u001b[33m\"\u001b[39m] = headers\n\u001b[32m    660\u001b[39m stringified_response = response.model_dump()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repos/personal/obsidian-llm-tool-use/.venv/lib/python3.12/site-packages/litellm/litellm_core_utils/logging_utils.py:149\u001b[39m, in \u001b[36mtrack_llm_api_timing.<locals>.decorator.<locals>.sync_wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    147\u001b[39m start_time = datetime.now()\n\u001b[32m    148\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m149\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    150\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repos/personal/obsidian-llm-tool-use/.venv/lib/python3.12/site-packages/litellm/llms/openai/openai.py:453\u001b[39m, in \u001b[36mOpenAIChatCompletion.make_sync_openai_chat_completion_request\u001b[39m\u001b[34m(self, openai_client, data, timeout, logging_obj)\u001b[39m\n\u001b[32m    451\u001b[39m raw_response = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    452\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m453\u001b[39m     raw_response = \u001b[43mopenai_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwith_raw_response\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    454\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    455\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    457\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(raw_response, \u001b[33m\"\u001b[39m\u001b[33mheaders\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    458\u001b[39m         headers = \u001b[38;5;28mdict\u001b[39m(raw_response.headers)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repos/personal/obsidian-llm-tool-use/.venv/lib/python3.12/site-packages/openai/_legacy_response.py:364\u001b[39m, in \u001b[36mto_raw_response_wrapper.<locals>.wrapped\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    360\u001b[39m extra_headers[RAW_RESPONSE_HEADER] = \u001b[33m\"\u001b[39m\u001b[33mtrue\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    362\u001b[39m kwargs[\u001b[33m\"\u001b[39m\u001b[33mextra_headers\u001b[39m\u001b[33m\"\u001b[39m] = extra_headers\n\u001b[32m--> \u001b[39m\u001b[32m364\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cast(LegacyAPIResponse[R], \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repos/personal/obsidian-llm-tool-use/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py:287\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    285\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    286\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m287\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repos/personal/obsidian-llm-tool-use/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py:925\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    882\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    883\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m    884\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    922\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m    923\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m    924\u001b[39m     validate_response_format(response_format)\n\u001b[32m--> \u001b[39m\u001b[32m925\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    926\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    927\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    928\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    929\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    931\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    933\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    934\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    935\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    936\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    937\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    938\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    939\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    940\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    941\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    942\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    947\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    948\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    949\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    950\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    951\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    952\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    953\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    954\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    955\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    956\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    957\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    958\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    959\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    960\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    961\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[32m    962\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m    963\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    964\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    965\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    966\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    967\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    968\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    969\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    970\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repos/personal/obsidian-llm-tool-use/.venv/lib/python3.12/site-packages/openai/_base_client.py:1239\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1225\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1226\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1227\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1234\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1235\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1236\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1237\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1238\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1239\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repos/personal/obsidian-llm-tool-use/.venv/lib/python3.12/site-packages/openai/_base_client.py:969\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m    967\u001b[39m response = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    968\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m969\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    970\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_should_stream_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    972\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    973\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    974\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.TimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    975\u001b[39m     log.debug(\u001b[33m\"\u001b[39m\u001b[33mEncountered httpx.TimeoutException\u001b[39m\u001b[33m\"\u001b[39m, exc_info=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repos/personal/obsidian-llm-tool-use/.venv/lib/python3.12/site-packages/httpx/_client.py:914\u001b[39m, in \u001b[36mClient.send\u001b[39m\u001b[34m(self, request, stream, auth, follow_redirects)\u001b[39m\n\u001b[32m    910\u001b[39m \u001b[38;5;28mself\u001b[39m._set_timeout(request)\n\u001b[32m    912\u001b[39m auth = \u001b[38;5;28mself\u001b[39m._build_request_auth(request, auth)\n\u001b[32m--> \u001b[39m\u001b[32m914\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    915\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    916\u001b[39m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    918\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    921\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repos/personal/obsidian-llm-tool-use/.venv/lib/python3.12/site-packages/httpx/_client.py:942\u001b[39m, in \u001b[36mClient._send_handling_auth\u001b[39m\u001b[34m(self, request, auth, follow_redirects, history)\u001b[39m\n\u001b[32m    939\u001b[39m request = \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[32m    941\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m942\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    947\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    948\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repos/personal/obsidian-llm-tool-use/.venv/lib/python3.12/site-packages/httpx/_client.py:979\u001b[39m, in \u001b[36mClient._send_handling_redirects\u001b[39m\u001b[34m(self, request, follow_redirects, history)\u001b[39m\n\u001b[32m    976\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mrequest\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m    977\u001b[39m     hook(request)\n\u001b[32m--> \u001b[39m\u001b[32m979\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    981\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m\"\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repos/personal/obsidian-llm-tool-use/.venv/lib/python3.12/site-packages/httpx/_client.py:1014\u001b[39m, in \u001b[36mClient._send_single_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m   1009\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1010\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1011\u001b[39m     )\n\u001b[32m   1013\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=request):\n\u001b[32m-> \u001b[39m\u001b[32m1014\u001b[39m     response = \u001b[43mtransport\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, SyncByteStream)\n\u001b[32m   1018\u001b[39m response.request = request\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repos/personal/obsidian-llm-tool-use/.venv/lib/python3.12/site-packages/httpx/_transports/default.py:250\u001b[39m, in \u001b[36mHTTPTransport.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    237\u001b[39m req = httpcore.Request(\n\u001b[32m    238\u001b[39m     method=request.method,\n\u001b[32m    239\u001b[39m     url=httpcore.URL(\n\u001b[32m   (...)\u001b[39m\u001b[32m    247\u001b[39m     extensions=request.extensions,\n\u001b[32m    248\u001b[39m )\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp.stream, typing.Iterable)\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[32m    255\u001b[39m     status_code=resp.status,\n\u001b[32m    256\u001b[39m     headers=resp.headers,\n\u001b[32m    257\u001b[39m     stream=ResponseStream(resp.stream),\n\u001b[32m    258\u001b[39m     extensions=resp.extensions,\n\u001b[32m    259\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repos/personal/obsidian-llm-tool-use/.venv/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py:256\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    253\u001b[39m         closing = \u001b[38;5;28mself\u001b[39m._assign_requests_to_connections()\n\u001b[32m    255\u001b[39m     \u001b[38;5;28mself\u001b[39m._close_connections(closing)\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    258\u001b[39m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[32m    259\u001b[39m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[32m    260\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, typing.Iterable)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repos/personal/obsidian-llm-tool-use/.venv/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py:236\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    232\u001b[39m connection = pool_request.wait_for_connection(timeout=timeout)\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    235\u001b[39m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m     response = \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[32m    240\u001b[39m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[32m    241\u001b[39m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[32m    242\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    243\u001b[39m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[32m    244\u001b[39m     pool_request.clear_connection()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repos/personal/obsidian-llm-tool-use/.venv/lib/python3.12/site-packages/httpcore/_sync/connection.py:103\u001b[39m, in \u001b[36mHTTPConnection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    100\u001b[39m     \u001b[38;5;28mself\u001b[39m._connect_failed = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    101\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repos/personal/obsidian-llm-tool-use/.venv/lib/python3.12/site-packages/httpcore/_sync/http11.py:136\u001b[39m, in \u001b[36mHTTP11Connection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    134\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[33m\"\u001b[39m\u001b[33mresponse_closed\u001b[39m\u001b[33m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    135\u001b[39m         \u001b[38;5;28mself\u001b[39m._response_closed()\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repos/personal/obsidian-llm-tool-use/.venv/lib/python3.12/site-packages/httpcore/_sync/http11.py:106\u001b[39m, in \u001b[36mHTTP11Connection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     95\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[32m     98\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mreceive_response_headers\u001b[39m\u001b[33m\"\u001b[39m, logger, request, kwargs\n\u001b[32m     99\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    100\u001b[39m     (\n\u001b[32m    101\u001b[39m         http_version,\n\u001b[32m    102\u001b[39m         status,\n\u001b[32m    103\u001b[39m         reason_phrase,\n\u001b[32m    104\u001b[39m         headers,\n\u001b[32m    105\u001b[39m         trailing_data,\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    107\u001b[39m     trace.return_value = (\n\u001b[32m    108\u001b[39m         http_version,\n\u001b[32m    109\u001b[39m         status,\n\u001b[32m    110\u001b[39m         reason_phrase,\n\u001b[32m    111\u001b[39m         headers,\n\u001b[32m    112\u001b[39m     )\n\u001b[32m    114\u001b[39m network_stream = \u001b[38;5;28mself\u001b[39m._network_stream\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repos/personal/obsidian-llm-tool-use/.venv/lib/python3.12/site-packages/httpcore/_sync/http11.py:177\u001b[39m, in \u001b[36mHTTP11Connection._receive_response_headers\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    174\u001b[39m timeout = timeouts.get(\u001b[33m\"\u001b[39m\u001b[33mread\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m     event = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11.Response):\n\u001b[32m    179\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repos/personal/obsidian-llm-tool-use/.venv/lib/python3.12/site-packages/httpcore/_sync/http11.py:217\u001b[39m, in \u001b[36mHTTP11Connection._receive_event\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    214\u001b[39m     event = \u001b[38;5;28mself\u001b[39m._h11_state.next_event()\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11.NEED_DATA:\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_network_stream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    227\u001b[39m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[32m    228\u001b[39m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[32m    229\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m data == \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._h11_state.their_state == h11.SEND_RESPONSE:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repos/personal/obsidian-llm-tool-use/.venv/lib/python3.12/site-packages/httpcore/_backends/sync.py:128\u001b[39m, in \u001b[36mSyncStream.read\u001b[39m\u001b[34m(self, max_bytes, timeout)\u001b[39m\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[32m    127\u001b[39m     \u001b[38;5;28mself\u001b[39m._sock.settimeout(timeout)\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "pot_math = dspy.ProgramOfThought(\"question -> answer\", max_iters=3)\n",
    "print(pot_math(question=\"What is the third root of 963261?\").answer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d5da93",
   "metadata": {},
   "source": [
    "`MultiChainComparison`: Spins up `M` separate `ChainOfThought` traces, asks the LLM to vote-critique, and returns the best. Fastest way to logarithmically scale intelligence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d99e725",
   "metadata": {},
   "source": [
    "### Your Own Modules and Signatures\n",
    "\n",
    "Starting from the built-in ones, you can construct your own modules that include multiple LLM calls and complicated flows.\n",
    "\n",
    "Custom signatures work similarly. You can define multiple `InputField()` and `OutputField()`'s.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "69bed707",
   "metadata": {},
   "outputs": [],
   "source": [
    "#first, we'll tell it our birthday\n",
    "#and it figures out our sign\n",
    "class ZodiacSignature(dspy.Signature):\n",
    "    birth_day = dspy.InputField()\n",
    "    sign= dspy.OutputField(desc=\"Aries, Taurus, …, Pisces\")\n",
    "\n",
    "\n",
    "#then it creates a horoscope.\n",
    "class HoroscopeSignature(dspy.Signature):\n",
    "    sign= dspy.InputField(desc='Zodiac sign')\n",
    "    current_date= dspy.InputField(desc='In YYYY-MM-DD format')\n",
    "    horoscope= dspy.OutputField(desc=\"One-paragraph horoscope\")\n",
    "    lucky_numbers= dspy.OutputField(desc=\"Comma-separated lucky numbers\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0ca3c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction(\n",
      "    sign='Capricorn',\n",
      "    horoscope_reasoning='As a Capricorn, you are known for your discipline and ambition. On May 12, 2025, Mercury is in Gemini, which can bring communication and social activities to the forefront of your life. This transit might affect how you interact with colleagues or friends.',\n",
      "    horoscope='With Mercury in Gemini, expect a busy day filled with conversations and exchanges of ideas. Your focus on communication could lead to new connections or insights that align with your career goals. Stay open to networking opportunities as they can be beneficial for your professional growth. However, be mindful of multitasking; while it may seem like you have many balls in the air, try to keep them organized to avoid any mix-ups.',\n",
      "    lucky_numbers='8, 23, 37, 41, 59'\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from datetime import date\n",
    "\n",
    "\n",
    "class HoroscopeFromBirthday(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.predict_sign = dspy.Predict(ZodiacSignature)\n",
    "        self.create_horoscope=dspy.ChainOfThought(HoroscopeSignature)\n",
    "\n",
    "    def forward(self, birth_day:str):\n",
    "        #get the zodiac sign\n",
    "        sign_pred = self.predict_sign(birth_day=birth_day)\n",
    "        sign = sign_pred.sign\n",
    "        #create the horoscope\n",
    "        today = date.today()\n",
    "        horo_pred = self.create_horoscope(sign=sign,current_date=today)\n",
    "\n",
    "\n",
    "\n",
    "        #Prediction acts as the return type. A dictionary wrapper\n",
    "        return dspy.Prediction(\n",
    "            sign = sign,\n",
    "            horoscope_reasoning = horo_pred.reasoning,\n",
    "            horoscope = horo_pred.horoscope,\n",
    "            lucky_numbers = horo_pred.lucky_numbers\n",
    "        )\n",
    "\n",
    "\n",
    "zodiac_finder=HoroscopeFromBirthday()\n",
    "print(zodiac_finder(birth_day=\"I was born on december 25, 2000\"))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75ff605",
   "metadata": {},
   "source": [
    "Here's a more complicated one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9ee49318",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/12 20:51:42 ERROR dspy.predict.program_of_thought: Error in code execution: Invalid Python syntax. message: \n",
      "2025/05/12 20:52:22 ERROR dspy.predict.program_of_thought: Error in code execution: Invalid Python syntax. message: \n",
      "2025/05/12 20:53:19 ERROR dspy.predict.program_of_thought: Error in code execution: Invalid Python syntax. message: \n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Max hops reached. Failed to run ProgramOfThought: Invalid Python syntax. message: ",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 54\u001b[39m\n\u001b[32m     49\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mdict\u001b[39m(story=story, quiz=quiz, tweet=tweet, inspo=blurbs)\n\u001b[32m     53\u001b[39m lab = StoryPuzzleLab()\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m res = \u001b[43mlab\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mLost temple, steam-age explorers\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m— STORY —\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,res[\u001b[33m\"\u001b[39m\u001b[33mstory\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     56\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m— QUIZ —\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,res[\u001b[33m'\u001b[39m\u001b[33mquiz\u001b[39m\u001b[33m'\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repos/personal/obsidian-llm-tool-use/.venv/lib/python3.12/site-packages/dspy/utils/callback.py:326\u001b[39m, in \u001b[36mwith_callbacks.<locals>.sync_wrapper\u001b[39m\u001b[34m(instance, *args, **kwargs)\u001b[39m\n\u001b[32m    324\u001b[39m callbacks = _get_active_callbacks(instance)\n\u001b[32m    325\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m callbacks:\n\u001b[32m--> \u001b[39m\u001b[32m326\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    328\u001b[39m call_id = uuid.uuid4().hex\n\u001b[32m    330\u001b[39m _execute_start_callbacks(instance, fn, call_id, callbacks, args, kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repos/personal/obsidian-llm-tool-use/.venv/lib/python3.12/site-packages/dspy/primitives/program.py:32\u001b[39m, in \u001b[36mModule.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     29\u001b[39m         output.set_lm_usage(usage_tracker.get_total_tokens())\n\u001b[32m     30\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m output\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 45\u001b[39m, in \u001b[36mStoryPuzzleLab.forward\u001b[39m\u001b[34m(self, topic)\u001b[39m\n\u001b[32m     43\u001b[39m blurbs   = \u001b[38;5;28mself\u001b[39m.inspirer(topic=topic).blurbs\n\u001b[32m     44\u001b[39m outline  = \u001b[38;5;28mself\u001b[39m.plotter(topic=topic, blurbs=blurbs).outline\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m story    = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpuzzler\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutline\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutline\u001b[49m\u001b[43m)\u001b[49m.story\n\u001b[32m     46\u001b[39m quiz     = \u001b[38;5;28mself\u001b[39m.quizzer(story=story).questions\n\u001b[32m     47\u001b[39m tweet    = \u001b[38;5;28mself\u001b[39m.teaser(story=story).tweet\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repos/personal/obsidian-llm-tool-use/.venv/lib/python3.12/site-packages/dspy/utils/callback.py:326\u001b[39m, in \u001b[36mwith_callbacks.<locals>.sync_wrapper\u001b[39m\u001b[34m(instance, *args, **kwargs)\u001b[39m\n\u001b[32m    324\u001b[39m callbacks = _get_active_callbacks(instance)\n\u001b[32m    325\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m callbacks:\n\u001b[32m--> \u001b[39m\u001b[32m326\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    328\u001b[39m call_id = uuid.uuid4().hex\n\u001b[32m    330\u001b[39m _execute_start_callbacks(instance, fn, call_id, callbacks, args, kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repos/personal/obsidian-llm-tool-use/.venv/lib/python3.12/site-packages/dspy/primitives/program.py:32\u001b[39m, in \u001b[36mModule.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     29\u001b[39m         output.set_lm_usage(usage_tracker.get_total_tokens())\n\u001b[32m     30\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m output\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repos/personal/obsidian-llm-tool-use/.venv/lib/python3.12/site-packages/dspy/predict/program_of_thought.py:188\u001b[39m, in \u001b[36mProgramOfThought.forward\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m    186\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m hop == \u001b[38;5;28mself\u001b[39m.max_iters:\n\u001b[32m    187\u001b[39m     \u001b[38;5;28mself\u001b[39m.interpreter.shutdown()\n\u001b[32m--> \u001b[39m\u001b[32m188\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMax hops reached. Failed to run ProgramOfThought: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    189\u001b[39m input_kwargs.update({\u001b[33m\"\u001b[39m\u001b[33mprevious_code\u001b[39m\u001b[33m\"\u001b[39m: code, \u001b[33m\"\u001b[39m\u001b[33merror\u001b[39m\u001b[33m\"\u001b[39m: error})\n\u001b[32m    190\u001b[39m code_data = \u001b[38;5;28mself\u001b[39m.code_regenerate(**input_kwargs)\n",
      "\u001b[31mRuntimeError\u001b[39m: Max hops reached. Failed to run ProgramOfThought: Invalid Python syntax. message: "
     ]
    }
   ],
   "source": [
    "class FindInspo(dspy.Signature):\n",
    "    topic   = dspy.InputField()\n",
    "    blurbs  = dspy.OutputField(format=list, desc=\"3-5 catchy micro-blurbs\")\n",
    "\n",
    "class DraftPlot(dspy.Signature):\n",
    "    topic   = dspy.InputField()\n",
    "    blurbs  = dspy.InputField(format=list)\n",
    "    outline = dspy.OutputField(desc=\"bullet outline of the plot\")\n",
    "\n",
    "class InsertPuzzle(dspy.Signature):\n",
    "    outline = dspy.InputField()\n",
    "    story   = dspy.OutputField(desc=\"short story that embeds a logic puzzle\")\n",
    "\n",
    "class BuildQuiz(dspy.Signature):\n",
    "    story      = dspy.InputField()\n",
    "    questions  = dspy.OutputField(\n",
    "        format=list,\n",
    "        desc=\"list of (Q, choices:list, correct:str) tuples\")\n",
    "\n",
    "class TeaseTweet(dspy.Signature):\n",
    "    story = dspy.InputField()\n",
    "    tweet = dspy.OutputField(desc=\"≤280-char teaser\")\n",
    "\n",
    "\n",
    "# ── 2. Custom module (3 distinct DSPy modules) ───────────────────\n",
    "class StoryPuzzleLab(dspy.Module):\n",
    "    \"\"\"\n",
    "    Modules used →\n",
    "      ① ChainOfThought         – inspirations & quiz\n",
    "      ② ChainOfThoughtWithHint – plot expansion\n",
    "      ③ ProgramOfThought       – code-driven puzzle generation\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.inspirer = dspy.ChainOfThought(FindInspo, n=1)\n",
    "        self.plotter  = dspy.ChainOfThoughtWithHint(DraftPlot)\n",
    "        self.puzzler  = dspy.ProgramOfThought(InsertPuzzle, max_iters=3)\n",
    "        self.quizzer  = dspy.ChainOfThought(BuildQuiz)\n",
    "        self.teaser   = dspy.ChainOfThought(TeaseTweet, max_len=70)  # ≈ tweet\n",
    "\n",
    "    def forward(self, topic: str):\n",
    "        blurbs   = self.inspirer(topic=topic).blurbs\n",
    "        outline  = self.plotter(topic=topic, blurbs=blurbs).outline\n",
    "        story    = self.puzzler(outline=outline).story\n",
    "        quiz     = self.quizzer(story=story).questions\n",
    "        tweet    = self.teaser(story=story).tweet\n",
    "\n",
    "        return dict(story=story, quiz=quiz, tweet=tweet, inspo=blurbs)\n",
    "\n",
    "\n",
    "\n",
    "lab = StoryPuzzleLab()\n",
    "res = lab(\"Lost temple, steam-age explorers\")\n",
    "print(\"\\n— INSPIRATION —\\n\", res[\"inspo\"])\n",
    "print(\"\\n— STORY —\\n\",res[\"story\"])\n",
    "print(\"\\n— QUIZ —\\n\",res['quiz'])\n",
    "print(\"\\n— TWEET —\\n\", res[\"tweet\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a7dfc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a steam-age world, ancient civilizations are being rediscovered. Dr. Amelia Hartley, equipped with a steam-powered microscope, Eliot Blackwood with his clockwork compass, and Lila Voss with her invisibility cloak form an exploratory team. They stumble upon clues leading to a lost temple, filled with historical artifacts and puzzles. Navigating through the temple's traps using Dr. Hartley's microscope to identify safe paths, solving riddles that unlock secret passages with Eliot's compass, and avoiding detection by temple guardians with Lila's cloak are key parts of their journey. A confrontation with a mechanical guardian within the temple tests their skills and gadgets. Uncovering the secrets of the lost civilization, they decide to share knowledge responsibly.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0cf46923",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(res['quiz'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aeb2384",
   "metadata": {},
   "source": [
    "## So What?: Optimizers\n",
    "\n",
    "The syntax is nice and simple and whatever but what's so special about DSPy?\n",
    "\n",
    "Optimizers are applied at every system prompt that's contained withing your graph of agentic LLM calls. It mutates all the *learnable parameters*: prompt templates, demonstration pools, adaptor weights. It runs a *generate* > *score* > *selectt* loop. It proposes new demos or instructions, runs the module, evaluates the output against a metric function, and keeps the best variants for the next time around. \n",
    "\n",
    "Each Optimizer accepts three arguments: \n",
    "- a `Module`\n",
    "- a metric function that returns a float\n",
    "- train/validation data: 10-300 `Examples`\n",
    "\n",
    "Optimizers can be saved to json using `save()` and autologged to MLFlow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce02afed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "56363a80",
   "metadata": {},
   "source": [
    "## Going Larger: Programs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
