{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a865a950",
   "metadata": {},
   "source": [
    "Links\n",
    "- [DSPy Documentation](https://dspy.ai/#__tabbed_1_4)\n",
    "\n",
    "\n",
    "Double Saved to `obsidian-llm-tool-use` Github repo and my personal note vault in obsidian via:\n",
    "```bash\n",
    "jupytext --to markdown dspy_modules/intro_to_dspy.ipynb -o ~/Obsidian/Notes\\ Vault/intro_to_dspy.md\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09674048",
   "metadata": {},
   "source": [
    "First, import the package and setup your llm calling configuration. For this, we'll be using ollama."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5efa3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "lm = dspy.LM('openai/qwen2.5:7b-instruct-q4_K_M', api_base='http://localhost:11434/v1', api_key='')\n",
    "dspy.configure(lm=lm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e980b6f0",
   "metadata": {},
   "source": [
    "Lets do the basic prompt-response: just use the `lm` as a function!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba8b1023",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Sure, this certainly seems like a test! How can I help you with it? Whether it's a language comprehension test, a creativity challenge, or something else entirely, feel free to provide more details so I can assist you better.\"]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm(\"Say this is a test!\", temperature=0.7)  # => ['This is a test!']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78536af",
   "metadata": {},
   "source": [
    "Super compact syntax.\n",
    "\n",
    "You could just use this as a nice way to make your LLM calls a bit more pythonic.\n",
    "\n",
    "You can also send using the chat completions formatting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf846a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm(messages=[{\"role\": \"user\", \"content\": \"Say this is a test!\"}])  # => ['This is a test!']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555bb837",
   "metadata": {},
   "source": [
    "Ok now to the first main topic:\n",
    "\n",
    "## Modules\n",
    "\n",
    "Modules help you describe AI behavior as *code*. not *strings*.\n",
    "\n",
    "You specify a *Signature*: a string that defines an input-output behavior: `\"question -> answer: float\"` \n",
    "\n",
    "Then you select a *Module* to assign a strategy for invoking the LLM. `Predict` is the simplest one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0fa9660e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completions(\n",
      "    answer=[2.0]\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "solve_math = dspy.Predict(\"question -> answer: float\")\n",
    "result = solve_math(question=\"What is 1 + 1?\")\n",
    "print(result.completions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225e99f1",
   "metadata": {},
   "source": [
    "A Module:\n",
    "- wraps a signature.\n",
    "- is callable\n",
    "- carries \"learnable parameters\" that DSPy can run optimization on.\n",
    "- composes: modules call other modules, can be stored as `json`, or be nested inside larger `dspy.Program` graphs.\n",
    "- persists: `module.save()`/`load()` for controlling state.\n",
    "\n",
    "\n",
    "There's a few really powerful primative ones already implemented, like `dspy.ChainOfThought`. It automatically:\n",
    "1. Inserts an instruction telling the LLM to show its reasoning.\n",
    "2. Adds an implicit extra output field called `reasoning`.\n",
    "3. Returns both the reasoning and the final answer, while still respecting the original signature.\n",
    "\n",
    "So that's why it won't be very good for:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d3e7d7bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completions(\n",
      "    reasoning=['To find the third root of 963261, we need to calculate 963261^(1/3).'],\n",
      "    answer=[45.0]\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "result = solve_math(question=\"What is the third root of 963261?\")\n",
    "print(result.completions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6218c0e8",
   "metadata": {},
   "source": [
    "But you can get pretty creative with the signatures.  LLM act as this universal function approximator written via English.  Modules try to shape that approximator into a math function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce8591a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyboard\n"
     ]
    }
   ],
   "source": [
    "solve_riddle = dspy.ChainOfThought(\"riddle -> answer\")\n",
    "print(solve_riddle(riddle=\"What has keys but can't open locks?\").answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff51c38",
   "metadata": {},
   "source": [
    "In your *Signature* you can list multiple fields: `\"context: list[str], question -> answer\"` or omit the types if they're strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aa95f473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completions(\n",
      "    reasoning=['The story describes a tense situation where the main character is being chased by Shia LaBeouf in an eerie, almost supernatural way. The elements of fear, suspense, and the unexpected turn of events (Shia LaBeouf as a cannibal) are key to the narrative.'],\n",
      "    emoji_sequence=['ðŸƒ\\u200dâ™‚ï¸ðŸ‘€ðŸ”ªðŸŒ³ðŸ§Ÿ\\u200dâ™‚ï¸ðŸŒ²ðŸƒ\\u200dâ™€ï¸ðŸ”ðŸ§·slaughteringä¸€è‡´å¥½è¯„ðŸ”¥']\n",
      ")\n",
      "ðŸƒâ€â™‚ï¸ðŸ‘€ðŸ”ªðŸŒ³ðŸ§Ÿâ€â™‚ï¸ðŸŒ²ðŸƒâ€â™€ï¸ðŸ”ðŸ§·slaughteringä¸€è‡´å¥½è¯„ðŸ”¥\n"
     ]
    }
   ],
   "source": [
    "emojify = dspy.ChainOfThought(\"story -> emoji_sequence\")\n",
    "\n",
    "story=\"\"\"You're walking in the woods\n",
    "There's no one around and your phone is dead\n",
    "Out of the corner of your eye you spot him\n",
    "Shia LaBeouf\n",
    "\n",
    "He's following you, about 30 feet back\n",
    "He gets down on all fours and breaks into a sprint\n",
    "He's gaining on you\n",
    "Shia LaBeouf\n",
    "\n",
    "You're looking for you car but you're all turned around\n",
    "He's almost upon you now\n",
    "And you can see there's blood on his face\n",
    "My God, there's blood everywhere!\n",
    "\n",
    "Running for you life (from Shia LaBeouf)\n",
    "He's brandishing a knife (it's Shia LaBeouf)\n",
    "Lurking in the shadows\n",
    "Hollywood superstar Shia LaBeouf\n",
    "\n",
    "Living in the woods (Shia LaBeouf)\n",
    "Killing for sport (Shia LaBeouf)\n",
    "Eating all the bodies\n",
    "Actual cannibal Shia LaBeouf\"\"\"\n",
    "\n",
    "emoji_sequence = emojify(story=story)\n",
    "print(emoji_sequence.completions)\n",
    "print(emoji_sequence.emoji_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f0d27890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stai camminando nel bosco\n",
      "Non c'Ã¨ nessuno intorno e il tuo cellulare non funziona\n",
      "Dalla parte del tuo occhio destro lo vedi\n",
      "Shia LaBeouf\n",
      "\n",
      "Lo sta seguendo, a circa 30 piedi di distanza\n",
      "Si mette in quattro zampe e scatta in corsa\n",
      "Sta guadagnando terreno\n",
      "Shia LaBeouf\n",
      "\n",
      "Cercavi la tua macchina ma ti sei girato tutto intorno\n",
      "Ora Ã¨ quasi sopra di te\n",
      "E puoi vedere che c'Ã¨ sangue sul suo viso\n",
      "Dio mio, c'Ã¨ sangue dappertutto!\n",
      "\n",
      "Correndo per la tua vita (da Shia LaBeouf)\n",
      "Sta brandendo un coltello (Ã¨ Shia LaBeouf)\n",
      "Si aggira nelle ombre\n",
      "Superstite hollywoodiano Shia LaBeouf\n",
      "\n",
      "Vivere nel bosco (Shia LaBeouf)\n",
      "Uccidendo a sangue caldo (Shia LaBeouf)\n",
      "Mangiando tutti i corpi\n",
      "Cannibale reale Shia LaBeouf\n"
     ]
    }
   ],
   "source": [
    "translate = dspy.ChainOfThought(\"string -> italian\")\n",
    "translation = translate(string=story)\n",
    "print(translation.italian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9a0abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completions(\n",
      "    reasoning=[\"The Fibonacci function is typically implemented using recursion or iteration. In this case, since no specific implementation details are provided, we will consider a basic recursive approach which has an exponential time complexity due to the repeated calculations of the same subproblems.\\n\\nFor the iterative approach, it would have a linear time complexity. However, without knowing the exact implementation, we'll assume the worst-case scenario for simplicity.\"],\n",
      "    time_complexity=['O(2^n)']\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "find_time_complexity = dspy.ChainOfThought(\"function -> time_complexity\")\n",
    "\n",
    "def fibonacci(n):\n",
    "    if n <= 1:\n",
    "        return n\n",
    "    else:\n",
    "        return fibonacci(n-1) + fibonacci(n-2)\n",
    "    \n",
    "complexity = find_time_complexity(function=fibonacci)\n",
    "print(complexity.completions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e506541",
   "metadata": {},
   "source": [
    "### Single-shot predictors\n",
    "\n",
    "There's `Predict`, `ChainOfThought`, and `ChainOfThoughtWithHint` as well.\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2146abd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We can use the distributive property of multiplication over addition to solve this problem. The hint suggests breaking down 17 into 10 + 7, so we have:\n",
      "\n",
      "\\[ 16 \\times 17 = 16 \\times (10 + 7) = (16 \\times 10) + (16 \\times 7) \\]\n",
      "\n",
      "Given that \\(16 \\times 10 = 160\\) and \\(16 \\times 7 = 112\\), we can add these two results together:\n",
      "\n",
      "\\[ 160 + 112 = 272 \\]\n",
      "\n",
      "Therefore, the answer is 272.\n",
      "----\n",
      "272.0\n"
     ]
    }
   ],
   "source": [
    "cot_hint = dspy.ChainOfThoughtWithHint(\"question -> answer: float\")\n",
    "prediction = cot_hint(question=\"What is 16â€¯Ã—â€¯17?\", hint=\"16Ã—10=160 and 16Ã—7=112\")  \n",
    "print(prediction.reasoning)\n",
    "print(\"----\")\n",
    "print(prediction.answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060bec9d",
   "metadata": {},
   "source": [
    "### Multi-shot Predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dcbfd6f",
   "metadata": {},
   "source": [
    "`ReAct`: implements a *ReAct* agent pattern: the LLM alternates between thinking and calling user-supplied tooks, and stops when it fills the Signature. Used for search-and-answer agents, code-execution helpers, custom tool use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "726249ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction(\n",
      "    trajectory={'thought_0': 'To find out how many R\\'s are in the word \"strawberry\", I can use the count_letters tool.', 'tool_name_0': 'count_letters', 'tool_args_0': {'string': 'strawberry'}, 'observation_0': {'s': 1, 't': 1, 'r': 3, 'a': 1, 'w': 1, 'b': 1, 'e': 1, 'y': 1}, 'thought_1': 'The count_letters tool returned that the word \"strawberry\" contains 3 \\'r\\'s. Since I have all the information needed to answer the question, I can now finish.', 'tool_name_1': 'finish', 'tool_args_1': {}, 'observation_1': 'Completed.'},\n",
      "    reasoning='To determine how many R\\'s are in the word \"strawberry\", I used a tool to count each letter. The result showed that there are 3 \\'r\\'s.',\n",
      "    answer=\"There are 3 R's in the word strawberry.\"\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# ReAct tool counts number of letter occurances in a string\n",
    "def count_letters(string: str) -> dict:\n",
    "    counts = {}\n",
    "    for letter in string:\n",
    "        if letter.isalpha():\n",
    "            counts[letter] = counts.get(letter, 0) + 1\n",
    "    return counts\n",
    "\n",
    "question_answerer = dspy.ReAct(\"question -> answer\",tools=[count_letters],max_iters=3)\n",
    "\n",
    "print(question_answerer(question=\"How many R's in the word strawberry?\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d5da93",
   "metadata": {},
   "source": [
    "`ProgramOfThought`: ask LLM to write a python program, runs using Deno, then passes result back into the answer. \n",
    "\n",
    "\n",
    "`MultiChainComparison`: Spins up `M` separate `ChainOfThought` traces, asks the LLM to vote-critique, and returns the best. Fastest way to logarithmically scale intelligence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d99e725",
   "metadata": {},
   "source": [
    "### Your Own Modules\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aeb2384",
   "metadata": {},
   "source": [
    "## So What?: Optimizers\n",
    "\n",
    "The syntax is nice and simple and whatever but what's so special about DSPy?\n",
    "\n",
    "Optimizers are applied at every system prompt that's contained withing your graph of agentic LLM calls. It mutates all the *learnable parameters*: prompt templates, demonstration pools, adaptor weights. It runs a *generate* > *score* > *selectt* loop. It proposes new demos or instructions, runs the module, evaluates the output against a metric function, and keeps the best variants for the next time around. \n",
    "\n",
    "Each Optimizer accepts three arguments: \n",
    "- a `Module`\n",
    "- a metric function that returns a float\n",
    "- train/validation data: 10-300 `Examples`\n",
    "\n",
    "Optimizers can be saved to json using `save()` and autologged to MLFlow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce02afed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "56363a80",
   "metadata": {},
   "source": [
    "## Going Larger: Programs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
